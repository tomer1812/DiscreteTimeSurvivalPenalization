{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pydts.examples_utils.generate_simulations_data import generate_quick_start_df\n",
    "from pydts.examples_utils.plots import plot_example_pred_output\n",
    "from pydts.examples_utils.plots import add_panel_text\n",
    "from pydts.fitters import TwoStagesFitter, DataExpansionFitter\n",
    "\n",
    "from pydts.data_generation import EventTimesSampler\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "import pickle\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "slicer = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = ''\n",
    "COEF_COL = '   coef   '\n",
    "STDERR_COL = ' std err '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_patients = 5000\n",
    "n_cov = 5\n",
    "d_times = 30\n",
    "j_events = 3\n",
    "covariates = [f'Z{i + 1}' for i in range(n_cov)]\n",
    "\n",
    "real_coef_dict = {\n",
    "    \"alpha\": {\n",
    "        1: lambda t: - 2.2 - 0.1 * np.log(t),\n",
    "        2: lambda t: - 2.3 - 0.1 * np.log(t),\n",
    "        3: lambda t: - 2.4 - 0.1 * np.log(t)\n",
    "    },\n",
    "    \"beta\": {\n",
    "        1: -np.log([2.5, 1.5, 0.8, 3, 2]),\n",
    "        2: -np.log([0.8, 3, 2.8, 2.2, 1.5]),\n",
    "        3: -np.log([1.8, 0.8, 2.5, 1.2, 3])\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "ets = EventTimesSampler(d_times=d_times, j_event_types=j_events)\n",
    "\n",
    "seed = 0\n",
    "\n",
    "\n",
    "patients_df = pd.DataFrame(data=pd.DataFrame(data=np.random.uniform(0,1, size=[n_patients, n_cov]),\n",
    "                           columns=covariates))\n",
    "\n",
    "patients_df = ets.sample_event_times(patients_df, hazard_coefs=real_coef_dict, seed=seed)\n",
    "patients_df = ets.sample_independent_lof_censoring(patients_df, prob_lof_at_t=0.01 * np.ones_like(ets.times))\n",
    "patients_df = ets.update_event_or_lof(patients_df)\n",
    "\n",
    "patients_df.index.name='pid'                 \n",
    "patients_df = patients_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pydts.examples_utils.plots import plot_events_occurrence\n",
    "plot_events_occurrence(patients_df[patients_df['X'] != 31])\n",
    "plot_events_occurrence(patients_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "patients_df[patients_df['J'] != 0].groupby(['X', 'J'])['pid'].count()[-40:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resample and Estimate K times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_patients_list = [5_000, 10_000, 15_000, 20_000] \n",
    "k_runs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for inp, n_patients in enumerate(n_patients_list):\n",
    "    case = f'Sample_size_{n_patients}_final_3comp_censoring_d30_'\n",
    "    \n",
    "    for k in range(k_runs):\n",
    "        try:\n",
    "            # Sampling based on different seed each time\n",
    "            loop_seed = 3000*inp+k+seed\n",
    "            print(f'Sampling Patients, loop seed: {loop_seed}')\n",
    "            np.random.seed(loop_seed)\n",
    "            patients_df = pd.DataFrame(data=pd.DataFrame(data=np.random.uniform(0,1, size=[n_patients, n_cov]),\n",
    "                                       columns=covariates))\n",
    "            \n",
    "            patients_df = ets.sample_event_times(patients_df, hazard_coefs=real_coef_dict, seed=loop_seed)\n",
    "            patients_df = ets.sample_independent_lof_censoring(patients_df, \n",
    "                                                               prob_lof_at_t=0.01 * np.ones_like(ets.times))\n",
    "            patients_df = ets.update_event_or_lof(patients_df)\n",
    "            patients_df.index.name='pid'\n",
    "            patients_df = patients_df.reset_index()\n",
    "\n",
    "            # Two step fitter\n",
    "            new_fitter = TwoStagesFitter()\n",
    "            print(case)\n",
    "            print(f'Starting two-step: {k+1}/{k_runs}')\n",
    "            two_step_start = time()\n",
    "            new_fitter.fit(df=patients_df.drop(['C', 'T'], axis=1), nb_workers=1)\n",
    "            two_step_end = time()\n",
    "            print(f'Finished two-step: {k+1}/{k_runs}, {two_step_end-two_step_start}sec')\n",
    "\n",
    "\n",
    "            # Lee et al fitter\n",
    "            lee_fitter = DataExpansionFitter()\n",
    "            print(f'Starting Lee: {k+1}/{k_runs}')\n",
    "            lee_start = time()\n",
    "            lee_fitter.fit(df=patients_df.drop(['C', 'T'], axis=1))\n",
    "            lee_end = time()\n",
    "            print(f'Finished lee: {k+1}/{k_runs}, {lee_end-lee_start}sec')\n",
    "\n",
    "\n",
    "            lee_alpha_ser = lee_fitter.get_alpha_df().loc[:, slicer[:, [COEF_COL, STDERR_COL] ]].unstack().sort_index()\n",
    "            lee_beta_ser = lee_fitter.get_beta_SE().loc[:, slicer[:, [COEF_COL, STDERR_COL] ]].unstack().sort_index()\n",
    "\n",
    "            if k == 0:\n",
    "                two_step_alpha_k_results = new_fitter.alpha_df[['J', 'X', 'alpha_jt']]\n",
    "                two_step_beta_k_results = new_fitter.get_beta_SE().unstack().to_frame()\n",
    "\n",
    "                lee_alpha_k_results = lee_alpha_ser.to_frame()\n",
    "                lee_beta_k_results = lee_beta_ser.to_frame()\n",
    "\n",
    "            else:\n",
    "                two_step_alpha_k_results = pd.concat([two_step_alpha_k_results, new_fitter.alpha_df['alpha_jt']], axis=1)\n",
    "                two_step_beta_k_results = pd.concat([two_step_beta_k_results, new_fitter.get_beta_SE().unstack()], axis=1)\n",
    "\n",
    "                lee_alpha_k_results = pd.concat([lee_alpha_k_results, lee_alpha_ser], axis=1)\n",
    "                lee_beta_k_results = pd.concat([lee_beta_k_results, lee_beta_ser], axis=1)\n",
    "\n",
    "            # Cache results\n",
    "            two_step_alpha_k_results.to_csv(os.path.join(OUTPUT_DIR, f'{case}_two_step_alpha_run_{k_runs}.csv'))\n",
    "            two_step_beta_k_results.to_csv(os.path.join(OUTPUT_DIR, f'{case}_two_step_beta_run_{k_runs}.csv'))\n",
    "            lee_alpha_k_results.to_csv(os.path.join(OUTPUT_DIR, f'{case}_lee_alpha_run_{k_runs}.csv'))\n",
    "            lee_beta_k_results.to_csv(os.path.join(OUTPUT_DIR, f'{case}_lee_beta_run_{k_runs}.csv'))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Failed during trial {k}')\n",
    "            print(e)\n",
    "            \n",
    "\n",
    "    two_step_alpha_k_results = two_step_alpha_k_results.set_index(['J', 'X'])\n",
    "    two_step_alpha_k_results.columns = list(range(1, 1+k_runs))\n",
    "    two_step_beta_k_results.columns = list(range(1, 1+k_runs))\n",
    "    lee_alpha_k_results.columns = list(range(1, 1+k_runs))\n",
    "    lee_beta_k_results.columns = list(range(1, 1+k_runs))\n",
    "\n",
    "    # Save results\n",
    "    two_step_alpha_k_results.to_csv(os.path.join(OUTPUT_DIR, f'{case}_two_step_alpha_run_{k_runs}.csv'))\n",
    "    two_step_beta_k_results.to_csv(os.path.join(OUTPUT_DIR, f'{case}_two_step_beta_run_{k_runs}.csv'))\n",
    "    lee_alpha_k_results.to_csv(os.path.join(OUTPUT_DIR, f'{case}_lee_alpha_run_{k_runs}.csv'))\n",
    "    lee_beta_k_results.to_csv(os.path.join(OUTPUT_DIR, f'{case}_lee_beta_run_{k_runs}.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_dfs = []\n",
    "\n",
    "for n_patients in n_patients_list: \n",
    "    case = f'Sample_size_{n_patients}_final_3comp_censoring_d30_'\n",
    "\n",
    "    two_step_alpha_k_results = pd.read_csv(os.path.join(OUTPUT_DIR, f'{case}_two_step_alpha_run_{k_runs}.csv'), \n",
    "                                           index_col=['J', 'X'])\n",
    "    two_step_beta_k_results = pd.read_csv(os.path.join(OUTPUT_DIR, f'{case}_two_step_beta_run_{k_runs}.csv'),\n",
    "                                          index_col=[0, 1])\n",
    "    lee_alpha_k_results = pd.read_csv(os.path.join(OUTPUT_DIR, f'{case}_lee_alpha_run_{k_runs}.csv'),\n",
    "                                      index_col=[0,1,2])\n",
    "    lee_beta_k_results = pd.read_csv(os.path.join(OUTPUT_DIR, f'{case}_lee_beta_run_{k_runs}.csv'),\n",
    "                                     index_col=[0, 1,2])\n",
    "\n",
    "    # Beta\n",
    "    \n",
    "    coverage_df = pd.DataFrame(index=two_step_beta_k_results.loc[['j1_params', 'j2_params', 'j3_params'], :].index,\n",
    "                               columns=two_step_beta_k_results.loc[['j1_params', 'j2_params', 'j3_params'], :].columns.astype(int))\n",
    "\n",
    "    true_col = np.concatenate([np.concatenate([real_coef_dict['beta'][1], real_coef_dict['beta'][2]]), real_coef_dict['beta'][3]])  \n",
    "\n",
    "    for idc, c in enumerate(covariates):\n",
    "        for run_id in range(len(two_step_beta_k_results.columns)):\n",
    "            est = two_step_beta_k_results.loc['j1_params', c][run_id]\n",
    "            se = two_step_beta_k_results.loc['j1_SE', c][run_id]\n",
    "            true_val = true_col[idc]\n",
    "            coverage_df.loc[('j1_params', c), run_id+1] = int(( (est - 1.96*se) <= true_val ) & ( (est + 1.96*se) >= true_val))\n",
    "\n",
    "            est = two_step_beta_k_results.loc['j2_params', c][run_id]\n",
    "            se = two_step_beta_k_results.loc['j2_SE', c][run_id]\n",
    "            true_val = true_col[idc + ((len(true_col)) // 3)]\n",
    "            coverage_df.loc[('j2_params', c), run_id+1] = int(( (est - 1.96*se) <= true_val ) & ( (est + 1.96*se) >= true_val))\n",
    "            \n",
    "            est = two_step_beta_k_results.loc['j3_params', c][run_id]\n",
    "            se = two_step_beta_k_results.loc['j3_SE', c][run_id]\n",
    "            true_val = true_col[idc + 2*((len(true_col)) // 3)]\n",
    "            coverage_df.loc[('j3_params', c), run_id+1] = int(( (est - 1.96*se) <= true_val ) & ( (est + 1.96*se) >= true_val))\n",
    "            \n",
    "    twostep_beta1_summary = two_step_beta_k_results.mean(axis=1).unstack([0]).round(3).iloc[:, [1,0]]\n",
    "    twostep_beta2_summary = two_step_beta_k_results.mean(axis=1).unstack([0]).round(3).iloc[:, [3,2]]\n",
    "    twostep_beta3_summary = two_step_beta_k_results.mean(axis=1).unstack([0]).round(3).iloc[:, [5,4]]\n",
    "\n",
    "    twostep_empirical_beta1 = two_step_beta_k_results.std(axis=1).unstack([0]).round(3).iloc[:, [1,0]].iloc[:, 0]\n",
    "    twostep_empirical_beta2 = two_step_beta_k_results.std(axis=1).unstack([0]).round(3).iloc[:, [3,2]].iloc[:, 0]\n",
    "    twostep_empirical_beta3 = two_step_beta_k_results.std(axis=1).unstack([0]).round(3).iloc[:, [5,4]].iloc[:, 0]\n",
    "\n",
    "    lee_beta1_summary = lee_beta_k_results.mean(axis=1).loc[slicer[1,:,:]].unstack([0]).round(3)\n",
    "    lee_beta2_summary = lee_beta_k_results.mean(axis=1).loc[slicer[2,:,:]].unstack([0]).round(3)\n",
    "    lee_beta3_summary = lee_beta_k_results.mean(axis=1).loc[slicer[3,:,:]].unstack([0]).round(3)\n",
    "\n",
    "\n",
    "    lee_beta1_summary.columns = pd.MultiIndex.from_tuples([('Lee et al.', 'Estimate'), ('Lee et al.', 'Estimated SE')])\n",
    "    lee_beta2_summary.columns = pd.MultiIndex.from_tuples([('Lee et al.', 'Estimate'), ('Lee et al.', 'Estimated SE')])\n",
    "    lee_beta3_summary.columns = pd.MultiIndex.from_tuples([('Lee et al.', 'Estimate'), ('Lee et al.', 'Estimated SE')])\n",
    "\n",
    "    beta_summary_comparison = pd.concat([lee_beta1_summary, lee_beta2_summary, lee_beta3_summary], axis=0)\n",
    "    beta_summary_comparison.index = [r'$\\beta_{11}$', r'$\\beta_{12}$', r'$\\beta_{13}$', r'$\\beta_{14}$', r'$\\beta_{15}$',\n",
    "                                     r'$\\beta_{21}$', r'$\\beta_{22}$', r'$\\beta_{23}$', r'$\\beta_{24}$', r'$\\beta_{25}$',\n",
    "                                     r'$\\beta_{31}$', r'$\\beta_{32}$', r'$\\beta_{33}$', r'$\\beta_{34}$', r'$\\beta_{35}$']\n",
    "    twostep_beta1_summary.columns = pd.MultiIndex.from_tuples([('two-step', 'Estimate'), ('two-step', 'Estimated SE')])\n",
    "    twostep_beta2_summary.columns = pd.MultiIndex.from_tuples([('two-step', 'Estimate'), ('two-step', 'Estimated SE')])\n",
    "    twostep_beta3_summary.columns = pd.MultiIndex.from_tuples([('two-step', 'Estimate'), ('two-step', 'Estimated SE')])\n",
    "\n",
    "    tmp = pd.concat([twostep_beta1_summary.round(3), twostep_beta2_summary.round(3), twostep_beta3_summary.round(3)], axis=0)\n",
    "    tmp.index = [r'$\\beta_{11}$', r'$\\beta_{12}$', r'$\\beta_{13}$', r'$\\beta_{14}$', r'$\\beta_{15}$',\n",
    "                 r'$\\beta_{21}$', r'$\\beta_{22}$', r'$\\beta_{23}$', r'$\\beta_{24}$', r'$\\beta_{25}$',\n",
    "                 r'$\\beta_{31}$', r'$\\beta_{32}$', r'$\\beta_{33}$', r'$\\beta_{34}$', r'$\\beta_{35}$']\n",
    "\n",
    "    tmp_std = pd.concat([twostep_empirical_beta1, twostep_empirical_beta2, twostep_empirical_beta3], axis=0).to_frame()\n",
    "    tmp_std.index = [r'$\\beta_{11}$', r'$\\beta_{12}$', r'$\\beta_{13}$', r'$\\beta_{14}$', r'$\\beta_{15}$',\n",
    "                     r'$\\beta_{21}$', r'$\\beta_{22}$', r'$\\beta_{23}$', r'$\\beta_{24}$', r'$\\beta_{25}$',\n",
    "                     r'$\\beta_{31}$', r'$\\beta_{32}$', r'$\\beta_{33}$', r'$\\beta_{34}$', r'$\\beta_{35}$']\n",
    "    tmp_std.columns = pd.MultiIndex.from_tuples([('two-step', 'Empirical SE')])\n",
    "\n",
    "    cov_series = ((coverage_df.sum(axis=1) / k_runs).round(3)).to_frame()\n",
    "    cov_series.index = [r'$\\beta_{11}$', r'$\\beta_{12}$', r'$\\beta_{13}$', r'$\\beta_{14}$', r'$\\beta_{15}$',\n",
    "                        r'$\\beta_{21}$', r'$\\beta_{22}$', r'$\\beta_{23}$', r'$\\beta_{24}$', r'$\\beta_{25}$',\n",
    "                        r'$\\beta_{31}$', r'$\\beta_{32}$', r'$\\beta_{33}$', r'$\\beta_{34}$', r'$\\beta_{35}$',]\n",
    "    cov_series.columns = pd.MultiIndex.from_tuples([('two-step', 'Coverage Rate')])\n",
    "    \n",
    "    beta_summary_comparison = pd.concat([beta_summary_comparison, tmp, tmp_std, cov_series], axis=1)\n",
    "    beta_summary_comparison.index.name =  r'$\\beta_{jk}$'\n",
    "\n",
    "\n",
    "    # True Values\n",
    "    beta_summary_comparison.insert(loc=0, column='True', value=true_col)\n",
    "    final_dfs.append(beta_summary_comparison.astype(float).round(3))\n",
    "    \n",
    "final_df = pd.concat(final_dfs, keys=n_patients_list)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(final_df.to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'alpha_different_n_J3_censoring.png'\n",
    "\n",
    "first_model_name = 'Lee et al.'\n",
    "second_model_name = 'two-step'\n",
    "times = range(1, d_times+1)\n",
    "\n",
    "lee_colors = ['tab:blue', 'tab:green', 'tab:red']\n",
    "two_step_colors = ['navy', 'darkgreen', 'tab:brown']\n",
    "true_colors = ['tab:blue', 'tab:green', 'tab:red']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 11))\n",
    "\n",
    "for idn, n_patients in enumerate(n_patients_list): \n",
    "    case = f'Sample_size_{n_patients}_final_3comp_censoring_d30_'\n",
    "      \n",
    "    np.random.seed(idn)\n",
    "    patients_df = pd.DataFrame(data=pd.DataFrame(data=np.random.uniform(0,1, size=[n_patients, n_cov]),\n",
    "                                 columns=covariates))\n",
    "\n",
    "    patients_df = ets.sample_event_times(patients_df, hazard_coefs=real_coef_dict, seed=seed)\n",
    "    patients_df = ets.sample_independent_lof_censoring(patients_df, \n",
    "                                                       prob_lof_at_t=0.01 * np.ones_like(ets.times))\n",
    "    patients_df = ets.update_event_or_lof(patients_df)\n",
    "    patients_df.index.name='pid'\n",
    "    patients_df = patients_df.reset_index()\n",
    "    counts = patients_df.groupby(['J', 'X'])['pid'].count().unstack('J').fillna(0)\n",
    "\n",
    "      \n",
    "    two_step_alpha_k_results = pd.read_csv(os.path.join(OUTPUT_DIR, f'{case}_two_step_alpha_run_{k_runs}.csv'), \n",
    "                                             index_col=['J', 'X'])\n",
    "\n",
    "    lee_alpha_k_results = pd.read_csv(os.path.join(OUTPUT_DIR, f'{case}_lee_alpha_run_{k_runs}.csv'),\n",
    "                                       index_col=[0,1,2])\n",
    "      \n",
    "    ax = axes[int(idn // 2), int(idn % 2)]\n",
    "    ax.set_title(f'n={n_patients}', fontsize=15)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "\n",
    "    for j in [1, 2, 3]:\n",
    "\n",
    "        tmp_alpha = lee_alpha_k_results.loc[slicer[j, COEF_COL, :]].mean(axis=1)\n",
    "        tmp_alpha.index = [int(idx.split(')[')[1].split(']')[0]) for idx in tmp_alpha.index]\n",
    "        tmp_alpha = pd.Series(tmp_alpha.values.squeeze().astype(float), index=tmp_alpha.index)\n",
    "   \n",
    "        ax.scatter(tmp_alpha.index, tmp_alpha.values,\n",
    "           label=f'J={j} ({first_model_name})', color=lee_colors[j-1], marker='o', alpha=0.4, s=40)\n",
    "\n",
    "        tmp_alpha = two_step_alpha_k_results.loc[slicer[j, :]].mean(axis=1)\n",
    "        ax.scatter(tmp_alpha.index, tmp_alpha.values.squeeze(),\n",
    "           label=f'J={j} ({second_model_name})', color=two_step_colors[j-1], marker='*', alpha=0.7, s=20)\n",
    "   \n",
    "        true_values = [real_coef_dict['alpha'][j](t) for t in times]\n",
    "        ax.plot(times, true_values, label=f'J={j} (True)', ls='--', color=true_colors[j-1])\n",
    "\n",
    "        ax.set_xlabel(r'Time', fontsize=18)\n",
    "        ax.set_ylabel(r'$\\alpha_{jt}$', fontsize=18)\n",
    "        ax.legend(loc='upper right', fontsize=12)\n",
    "        ax.set_ylim([-3.7, -0.7])\n",
    "    \n",
    "    ax2 = ax.twinx()\n",
    "    ax2.bar(counts.index, counts[1].values.squeeze(), label='J=1', color='navy', alpha=0.4, width=0.4)\n",
    "    ax2.bar(counts.index, counts[2].values.squeeze(), label='J=2', color='darkgreen', alpha=0.4, align='edge',\n",
    "            width=0.4)\n",
    "    ax2.bar(counts.index, counts[3].values.squeeze(), label='J=3', color='tab:red', alpha=0.6, align='edge',\n",
    "            width=-0.4)\n",
    "    ax2.legend(loc='upper center', fontsize=12)\n",
    "    ax2.set_ylabel('Number of observed events', fontsize=16, color='red')\n",
    "    ax2.tick_params(axis='y', colors='red')\n",
    "    ax2.set_ylim([0, 1700])\n",
    "    ax2.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax2.tick_params(axis='both', which='minor', labelsize=15)\n",
    "    \n",
    "fig.tight_layout()\n",
    "\n",
    "if filename is not None:\n",
    "    fig.savefig(os.path.join(OUTPUT_DIR, filename), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39-dtsp",
   "language": "python",
   "name": "py39-dtsp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}