{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pydts.examples_utils.generate_simulations_data import generate_quick_start_df\n",
    "from pydts.examples_utils.plots import plot_example_pred_output\n",
    "from pydts.examples_utils.plots import add_panel_text\n",
    "from pydts.fitters import TwoStagesFitter, DataExpansionFitter\n",
    "\n",
    "from pydts.data_generation import EventTimesSampler\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "import pickle\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "slicer = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = '/app/output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Sampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "real_coef_dict = {\n",
    "    \"alpha\": {\n",
    "        1: lambda t: -3.65 + 0.8 * np.log(t),\n",
    "        2: lambda t: -3.75 + 0.9 * np.log(t)\n",
    "    },\n",
    "    \"beta\": {\n",
    "        1: -np.log([0.8, 3.5, 3, 2.5, 2]),\n",
    "        2: -np.log([1, 3, 4, 3, 2.5])\n",
    "    }\n",
    "}\n",
    "\n",
    "n_patients = 15000\n",
    "n_cov = 5\n",
    "d_times = 40\n",
    "j_events = 2\n",
    "\n",
    "ets = EventTimesSampler(d_times=d_times, j_event_types=j_events)\n",
    "\n",
    "seed = 0\n",
    "\n",
    "covariates = [f'Z{i + 1}' for i in range(n_cov)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "COEF_COL = '   coef   '\n",
    "STDERR_COL = ' std err '"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "patients_df = pd.DataFrame(data=pd.DataFrame(data=np.random.uniform(0,1, size=[n_patients, n_cov]),\n",
    "                           columns=covariates))\n",
    "                           \n",
    "patients_df = ets.sample_event_times(patients_df, hazard_coefs=real_coef_dict, seed=seed)\n",
    "patients_df = ets.sample_independent_lof_censoring(patients_df, prob_los_at_t=0.005*np.ones_like(ets.times), seed=seed+1)\n",
    "patients_df = ets.update_event_or_lof(patients_df)\n",
    "\n",
    "patients_df.index.name='pid'                 \n",
    "patients_df = patients_df.reset_index()\n",
    "\n",
    "from pydts.examples_utils.plots import plot_events_occurrence\n",
    "plot_events_occurrence(patients_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "patients_df.groupby(['X', 'J'])['pid'].count()[-20:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run Simulations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for n_patients in [15_000, 20_000, 25_000]:\n",
    "    print('**************************************')\n",
    "    case = f'Sample_size_{n_patients}_rerun_'\n",
    "    k_runs = 200\n",
    "    two_step_fit_times = []\n",
    "    lee_fit_times = []\n",
    "\n",
    "    for k in range(k_runs):\n",
    "        try:\n",
    "            # Sampling based on different seed each time\n",
    "            np.random.seed(seed+k)\n",
    "            patients_df = pd.DataFrame(data=pd.DataFrame(data=np.random.uniform(0,1, size=[n_patients, n_cov]),\n",
    "                                       columns=covariates))\n",
    "\n",
    "            patients_df = ets.sample_event_times(patients_df, hazard_coefs=real_coef_dict, seed=seed)\n",
    "            patients_df = ets.sample_independent_lof_censoring(patients_df, prob_los_at_t=0.005*np.ones_like(ets.times), seed=seed+1)\n",
    "            patients_df = ets.update_event_or_lof(patients_df)\n",
    "            patients_df.index.name='pid'\n",
    "            patients_df = patients_df.reset_index()\n",
    "\n",
    "            # Two step fitter\n",
    "            new_fitter = TwoStagesFitter()\n",
    "            print(case)\n",
    "            print(f'Starting two-step: {k}')\n",
    "            two_step_start = time()\n",
    "            new_fitter.fit(df=patients_df.drop(['C', 'T'], axis=1), nb_workers=1)\n",
    "            two_step_end = time()\n",
    "            print(f'Finished two-step: {k}, {two_step_end-two_step_start}sec')\n",
    "\n",
    "\n",
    "            # Lee et al fitter\n",
    "            lee_fitter = DataExpansionFitter()\n",
    "            print(f'Starting Lee: {k}')\n",
    "            lee_start = time()\n",
    "            lee_fitter.fit(df=patients_df.drop(['C', 'T'], axis=1))\n",
    "            lee_end = time()\n",
    "            print(f'Finished lee: {k}, {lee_end-lee_start}sec')\n",
    "\n",
    "\n",
    "            lee_alpha_ser = lee_fitter.get_alpha_df().loc[:, slicer[:, [COEF_COL, STDERR_COL] ]].unstack().sort_index()\n",
    "            lee_beta_ser = lee_fitter.get_beta_SE().loc[:, slicer[:, [COEF_COL, STDERR_COL] ]].unstack().sort_index()\n",
    "\n",
    "\n",
    "            # Save results only if both fitters were successful\n",
    "            two_step_fit_times.append(two_step_end - two_step_start)\n",
    "            lee_fit_times.append(lee_end-lee_start)\n",
    "\n",
    "\n",
    "            if k == 0:\n",
    "                two_step_alpha_k_results = new_fitter.alpha_df[['J', 'X', 'alpha_jt']]\n",
    "                two_step_beta_k_results = new_fitter.get_beta_SE().unstack().to_frame()\n",
    "\n",
    "                lee_alpha_k_results = lee_alpha_ser.to_frame()\n",
    "                lee_beta_k_results = lee_beta_ser.to_frame()\n",
    "\n",
    "            else:\n",
    "                two_step_alpha_k_results = pd.concat([two_step_alpha_k_results, new_fitter.alpha_df['alpha_jt']], axis=1)\n",
    "                two_step_beta_k_results = pd.concat([two_step_beta_k_results, new_fitter.get_beta_SE().unstack()], axis=1)\n",
    "\n",
    "                lee_alpha_k_results = pd.concat([lee_alpha_k_results, lee_alpha_ser], axis=1)\n",
    "                lee_beta_k_results = pd.concat([lee_beta_k_results, lee_beta_ser], axis=1)\n",
    "\n",
    "            # Cache results\n",
    "            two_step_alpha_k_results.to_csv(os.path.join(OUTPUT_DIR, f'two_step_alpha_run_{k_runs}.csv'))\n",
    "            two_step_beta_k_results.to_csv(os.path.join(OUTPUT_DIR, f'two_step_beta_run_{k_runs}.csv'))\n",
    "            lee_alpha_k_results.to_csv(os.path.join(OUTPUT_DIR, f'lee_alpha_run_{k_runs}.csv'))\n",
    "            lee_beta_k_results.to_csv(os.path.join(OUTPUT_DIR, f'lee_beta_run_{k_runs}.csv'))\n",
    "            \n",
    "            with open(os.path.join(OUTPUT_DIR, f\"two_step_fit_times_{k_runs}\"), \"wb\") as fp: \n",
    "                pickle.dump(two_step_fit_times, fp)\n",
    "\n",
    "            with open(os.path.join(OUTPUT_DIR, f\"lee_fit_times_{k_runs}\"), \"wb\") as fp:   \n",
    "                pickle.dump(lee_fit_times, fp)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Failed during trial {k}')\n",
    "            print(e)\n",
    "            \n",
    "\n",
    "    two_step_alpha_k_results = two_step_alpha_k_results.set_index(['J', 'X'])\n",
    "    two_step_alpha_k_results.columns = list(range(1, 1+k_runs))\n",
    "    two_step_beta_k_results.columns = list(range(1, 1+k_runs))\n",
    "    lee_alpha_k_results.columns = list(range(1, 1+k_runs))\n",
    "    lee_beta_k_results.columns = list(range(1, 1+k_runs))\n",
    "\n",
    "\n",
    "    # Save results\n",
    "    two_step_alpha_k_results.to_csv(os.path.join(OUTPUT_DIR, f'{case}_two_step_alpha_run_{k_runs}.csv'))\n",
    "    two_step_beta_k_results.to_csv(os.path.join(OUTPUT_DIR, f'{case}_two_step_beta_run_{k_runs}.csv'))\n",
    "    lee_alpha_k_results.to_csv(os.path.join(OUTPUT_DIR, f'{case}_lee_alpha_run_{k_runs}.csv'))\n",
    "    lee_beta_k_results.to_csv(os.path.join(OUTPUT_DIR, f'{case}_lee_beta_run_{k_runs}.csv'))\n",
    "\n",
    "    with open(os.path.join(OUTPUT_DIR, f\"{case}_two_step_fit_times_{k_runs}\"), \"wb\") as fp: \n",
    "        pickle.dump(two_step_fit_times, fp)\n",
    "\n",
    "    with open(os.path.join(OUTPUT_DIR, f\"{case}_lee_fit_times_{k_runs}\"), \"wb\") as fp:   \n",
    "        pickle.dump(lee_fit_times, fp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read Results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "k_runs = 200\n",
    "\n",
    "final_dfs = []\n",
    "n_patients_list = [15_000, 20_000, 25_000]\n",
    "\n",
    "run_time_dfs = []\n",
    "\n",
    "for n_patients in n_patients_list: \n",
    "    print('**************************************')\n",
    "    case = f'Sample_size_{n_patients}_rerun_'\n",
    "    \n",
    "    with open(os.path.join(OUTPUT_DIR, f\"{case}_two_step_fit_times_{k_runs}\"), \"rb\") as fp: \n",
    "        two_step_fit_times = pickle.load(fp)\n",
    "\n",
    "    with open(os.path.join(OUTPUT_DIR, f\"{case}_lee_fit_times_{k_runs}\"), \"rb\") as fp:   \n",
    "        lee_fit_times = pickle.load(fp)\n",
    "    \n",
    "    run_time_dfs.append(pd.DataFrame([two_step_fit_times, lee_fit_times], \n",
    "             index=pd.MultiIndex.from_tuples([('two-step', n_patients), ('Lee et al.', n_patients)])))\n",
    "    \n",
    "    print(np.median(two_step_fit_times))\n",
    "    print(np.median(lee_fit_times))\n",
    "    \n",
    "    two_step_alpha_k_results = pd.read_csv(os.path.join(OUTPUT_DIR, f'{case}_two_step_alpha_run_{k_runs}.csv'), \n",
    "                                           index_col=['J', 'X'])\n",
    "    two_step_beta_k_results = pd.read_csv(os.path.join(OUTPUT_DIR, f'{case}_two_step_beta_run_{k_runs}.csv'),\n",
    "                                          index_col=[0, 1])\n",
    "    lee_alpha_k_results = pd.read_csv(os.path.join(OUTPUT_DIR, f'{case}_lee_alpha_run_{k_runs}.csv'),\n",
    "                                      index_col=[0,1,2])\n",
    "    lee_beta_k_results = pd.read_csv(os.path.join(OUTPUT_DIR, f'{case}_lee_beta_run_{k_runs}.csv'),\n",
    "                                     index_col=[0, 1,2])\n",
    "\n",
    "    # Beta\n",
    "    \n",
    "    coverage_df = pd.DataFrame(index=two_step_beta_k_results.loc[['j1_params', 'j2_params'], :].index,\n",
    "                           columns=two_step_beta_k_results.loc[['j1_params', 'j2_params'], :].columns.astype(int))\n",
    "\n",
    "    true_col = -np.log([0.8, 3, 3, 2.5, 2, 1, 3, 4, 3, 2])   \n",
    "\n",
    "    for idc, c in enumerate(covariates):\n",
    "        for run_id in range(len(two_step_beta_k_results.columns)):\n",
    "            est = two_step_beta_k_results.loc['j1_params', c][run_id]\n",
    "            se = two_step_beta_k_results.loc['j1_SE', c][run_id]\n",
    "            true_val = true_col[idc]\n",
    "            coverage_df.loc[('j1_params', c), run_id+1] = int(( (est - 1.96*se) <= true_val ) & ( (est + 1.96*se) >= true_val))\n",
    "\n",
    "\n",
    "            est = two_step_beta_k_results.loc['j2_params', c][run_id]\n",
    "            se = two_step_beta_k_results.loc['j2_SE', c][run_id]\n",
    "            true_val = true_col[idc + ((len(true_col)) // 2)]\n",
    "            coverage_df.loc[('j2_params', c), run_id+1] = int(( (est - 1.96*se) <= true_val ) & ( (est + 1.96*se) >= true_val))\n",
    "            \n",
    "            \n",
    "    twostep_beta1_summary = two_step_beta_k_results.mean(axis=1).unstack([0]).round(3).iloc[:, [1,0]]\n",
    "    twostep_beta2_summary = two_step_beta_k_results.mean(axis=1).unstack([0]).round(3).iloc[:, [3,2]]\n",
    "    twostep_empirical_beta1 = two_step_beta_k_results.std(axis=1).unstack([0]).round(3).iloc[:, [1,0]].iloc[:, 0]\n",
    "    twostep_empirical_beta2 = two_step_beta_k_results.std(axis=1).unstack([0]).round(3).iloc[:, [3,2]].iloc[:, 0]\n",
    "\n",
    "    lee_beta1_summary = lee_beta_k_results.mean(axis=1).loc[slicer[1,:,:]].unstack([0]).round(3)\n",
    "    lee_beta2_summary = lee_beta_k_results.mean(axis=1).loc[slicer[2,:,:]].unstack([0]).round(3)\n",
    "\n",
    "\n",
    "    lee_beta1_summary.columns = pd.MultiIndex.from_tuples([('Lee et al.', 'Estimate'), ('Lee et al.', 'Estimated SE')])\n",
    "    lee_beta2_summary.columns = pd.MultiIndex.from_tuples([('Lee et al.', 'Estimate'), ('Lee et al.', 'Estimated SE')])\n",
    "    beta_summary_comparison = pd.concat([lee_beta1_summary, lee_beta2_summary], axis=0)\n",
    "    beta_summary_comparison.index = [r'$\\beta_{11}$', r'$\\beta_{12}$', r'$\\beta_{13}$', r'$\\beta_{14}$', r'$\\beta_{15}$',\n",
    "                                     r'$\\beta_{21}$', r'$\\beta_{22}$', r'$\\beta_{23}$', r'$\\beta_{24}$', r'$\\beta_{25}$']\n",
    "    twostep_beta1_summary.columns = pd.MultiIndex.from_tuples([('two-step', 'Estimate'), ('two-step', 'Estimated SE')])\n",
    "    twostep_beta2_summary.columns = pd.MultiIndex.from_tuples([('two-step', 'Estimate'), ('two-step', 'Estimated SE')])\n",
    "    tmp = pd.concat([twostep_beta1_summary.round(3), twostep_beta2_summary.round(3)], axis=0)\n",
    "    tmp.index = [r'$\\beta_{11}$', r'$\\beta_{12}$', r'$\\beta_{13}$', r'$\\beta_{14}$', r'$\\beta_{15}$',\n",
    "                 r'$\\beta_{21}$', r'$\\beta_{22}$', r'$\\beta_{23}$', r'$\\beta_{24}$', r'$\\beta_{25}$']\n",
    "\n",
    "    tmp_std = pd.concat([twostep_empirical_beta1, twostep_empirical_beta2], axis=0).to_frame()\n",
    "    tmp_std.index = [r'$\\beta_{11}$', r'$\\beta_{12}$', r'$\\beta_{13}$', r'$\\beta_{14}$', r'$\\beta_{15}$',\n",
    "                 r'$\\beta_{21}$', r'$\\beta_{22}$', r'$\\beta_{23}$', r'$\\beta_{24}$', r'$\\beta_{25}$']\n",
    "    tmp_std.columns = pd.MultiIndex.from_tuples([('two-step', 'Empirical SE')])\n",
    "\n",
    "    cov_series = ((coverage_df.sum(axis=1) / k_runs).round(3)).to_frame()\n",
    "    cov_series.index = [r'$\\beta_{11}$', r'$\\beta_{12}$', r'$\\beta_{13}$', r'$\\beta_{14}$', r'$\\beta_{15}$',\n",
    "                 r'$\\beta_{21}$', r'$\\beta_{22}$', r'$\\beta_{23}$', r'$\\beta_{24}$', r'$\\beta_{25}$']\n",
    "    cov_series.columns = pd.MultiIndex.from_tuples([('two-step', 'Coverage Rate')])\n",
    "    \n",
    "    beta_summary_comparison = pd.concat([beta_summary_comparison, tmp, tmp_std, cov_series], axis=1)\n",
    "    beta_summary_comparison.index.name =  r'$\\beta_{jk}$'\n",
    "\n",
    "\n",
    "    # True Values\n",
    "    beta_summary_comparison.insert(loc=0, column='True', value=true_col)\n",
    "    final_dfs.append(beta_summary_comparison.astype(float).round(3))\n",
    "    \n",
    "final_df = pd.concat(final_dfs, keys=n_patients_list)\n",
    "final_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(final_df.to_latex(escape=False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lee_alpha_k_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_time = pd.concat(run_time_dfs)\n",
    "run_time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(run_time.mean(axis=1).to_frame().unstack(0).round(3).to_latex())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "k_runs = 200\n",
    "\n",
    "n_patients_list = [15_000, 20_000, 25_000]\n",
    "\n",
    "\n",
    "\n",
    "filename = 'alpha_different_n_.png'\n",
    "\n",
    "first_model_name = 'Lee et al.'\n",
    "second_model_name = 'two-step'\n",
    "times = range(1, d_times+1)\n",
    "\n",
    "lee_colors = ['tab:blue', 'tab:green']\n",
    "two_step_colors = ['navy', 'darkgreen']\n",
    "true_colors = ['tab:blue', 'tab:green']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 16))\n",
    "\n",
    "for idn, n_patients in enumerate(n_patients_list): \n",
    "    case = f'Sample_size_{n_patients}_rerun_'\n",
    "    \n",
    "    np.random.seed(idn)\n",
    "    patients_df = pd.DataFrame(data=pd.DataFrame(data=np.random.uniform(0,1, size=[n_patients, n_cov]),\n",
    "                               columns=covariates))\n",
    "\n",
    "    patients_df = ets.sample_event_times(patients_df, hazard_coefs=real_coef_dict, seed=seed)\n",
    "    patients_df = ets.sample_independent_lof_censoring(patients_df, prob_los_at_t=0.005*np.ones_like(ets.times), \n",
    "                                                       seed=seed+1)\n",
    "    patients_df = ets.update_event_or_lof(patients_df)\n",
    "    patients_df.index.name='pid'\n",
    "    patients_df = patients_df.reset_index()\n",
    "    counts = patients_df.groupby(['J', 'X'])['pid'].count().unstack('J').dropna()\n",
    "\n",
    "    \n",
    "    two_step_alpha_k_results = pd.read_csv(os.path.join(OUTPUT_DIR, f'{case}_two_step_alpha_run_{k_runs}.csv'), \n",
    "                                           index_col=['J', 'X'])\n",
    "\n",
    "    lee_alpha_k_results = pd.read_csv(os.path.join(OUTPUT_DIR, f'{case}_lee_alpha_run_{k_runs}.csv'),\n",
    "                                      index_col=[0,1,2])\n",
    "    \n",
    "    ax = axes[int(idn // 2), int(idn % 2)]\n",
    "    ax.set_title(f'N={n_patients}')\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "\n",
    "    for j in [1, 2]:\n",
    "\n",
    "        tmp_alpha = lee_alpha_k_results.loc[slicer[j, COEF_COL, :]].mean(axis=1)\n",
    "        tmp_alpha.index = [int(idx.split(')[')[1].split(']')[0]) for idx in tmp_alpha.index]\n",
    "        tmp_alpha = pd.Series(tmp_alpha.values.squeeze().astype(float), index=tmp_alpha.index)\n",
    "    \n",
    "        ax.scatter(tmp_alpha.index, tmp_alpha.values,\n",
    "           label=f'J={j} ({first_model_name})', color=lee_colors[j-1], marker='o', alpha=0.4, s=40)\n",
    "\n",
    "        tmp_alpha = two_step_alpha_k_results.loc[slicer[j, :]].mean(axis=1)\n",
    "        ax.scatter(tmp_alpha.index, tmp_alpha.values.squeeze(),\n",
    "           label=f'J={j} ({second_model_name})', color=two_step_colors[j-1], marker='*', alpha=0.7, s=20)\n",
    "    \n",
    "        true_values = [real_coef_dict['alpha'][j](t) for t in times]\n",
    "        ax.plot(times, true_values, label=f'J={j} (True)', ls='--', color=true_colors[j-1])\n",
    "\n",
    "        ax.set_xlabel(r'Time', fontsize=18)\n",
    "        ax.set_ylabel(r'$\\alpha_{t}$', fontsize=18)\n",
    "        ax.legend(loc='upper left', fontsize=12)\n",
    "        #ax.set_ylim([-3, 0.5])\n",
    "    \n",
    "    ax2 = ax.twinx()\n",
    "    ax2.bar(counts.index, counts[1].values.squeeze(), label='J=1', color='tab:red', alpha=0.4, width=0.5)\n",
    "    ax2.bar(counts.index, counts[2].values.squeeze(), label='J=2', color='tab:brown', alpha=0.6, align='edge',\n",
    "            width=0.5)\n",
    "    ax2.legend(loc='upper center', fontsize=12)\n",
    "    ax2.set_ylabel('Number of observed events', fontsize=16, color='red')\n",
    "    ax2.tick_params(axis='y', colors='red')\n",
    "    ax2.set_ylim([0,2500])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tmp_alpha = lee_alpha_k_results.loc[slicer[j, COEF_COL, :]].mean(axis=1)\n",
    "tmp_alpha.index = [int(idx.split(')[')[1].split(']')[0]) for idx in tmp_alpha.index]\n",
    "tmp_alpha = pd.Series(tmp_alpha.values.squeeze().astype(float), index=tmp_alpha.index)\n",
    "tmp_alpha"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_alpha = lee_alpha_k_results.loc[slicer[j, COEF_COL, :]].mean(axis=1)\n",
    "tmp_alpha.index = [int(idx.split(')[')[1].split(']')[0]) for idx in tmp_alpha.index]\n",
    "tmp_alpha = pd.Series(tmp_alpha.values.squeeze().astype(float), index=tmp_alpha.index)\n",
    "tmp_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_alpha = lee_alpha_k_results.loc[slicer[j, COEF_COL, :]].mean(axis=1)\n",
    "tmp_alpha.index = [int(idx.split(')[')[1].split(']')[0]) for idx in tmp_alpha.index]\n",
    "tmp_alpha = pd.Series(tmp_alpha.values.squeeze().astype(float), index=tmp_alpha.index)\n",
    "tmp_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10   -1.982340\n",
       "11   -2.000573\n",
       "12   -2.015583\n",
       "13   -2.032216\n",
       "14   -2.035612\n",
       "15   -2.041994\n",
       "16   -2.058343\n",
       "17   -2.063003\n",
       "18   -2.064579\n",
       "19   -2.073679\n",
       "1    -1.764881\n",
       "20   -2.076352\n",
       "21   -2.075812\n",
       "22   -2.082347\n",
       "23   -2.077652\n",
       "24   -2.092188\n",
       "25   -2.089552\n",
       "26   -2.089023\n",
       "27   -2.089427\n",
       "28   -2.098780\n",
       "29   -2.097718\n",
       "2    -1.823048\n",
       "30   -2.103069\n",
       "31   -2.100723\n",
       "32   -2.106856\n",
       "33   -2.114051\n",
       "34   -2.111807\n",
       "35   -2.126085\n",
       "36   -2.124012\n",
       "37   -2.128068\n",
       "38   -2.135266\n",
       "39   -2.158462\n",
       "3    -1.866213\n",
       "40   -2.160121\n",
       "41   -2.142882\n",
       "42   -2.152004\n",
       "43   -2.160157\n",
       "44   -2.161459\n",
       "45   -2.159425\n",
       "46   -2.182967\n",
       "47   -2.194953\n",
       "48   -2.174118\n",
       "49   -2.099736\n",
       "4    -1.894417\n",
       "50   -2.018544\n",
       "5    -1.915841\n",
       "6    -1.934400\n",
       "7    -1.946326\n",
       "8    -1.970904\n",
       "9    -1.975183\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_alpha = lee_alpha_k_results.loc[slicer[j, COEF_COL, :]].mean(axis=1)\n",
    "tmp_alpha.index = [int(idx.split(')[')[1].split(']')[0]) for idx in tmp_alpha.index]\n",
    "tmp_alpha = pd.Series(tmp_alpha.values.squeeze().astype(float), index=tmp_alpha.index)\n",
    "tmp_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}