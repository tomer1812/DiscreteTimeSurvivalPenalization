{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys \n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "%matplotlib inline\n",
    "sys.path.append('../')\n",
    "from src.plots import add_panel_text\n",
    "import numpy as np\n",
    "\n",
    "from src.constants import *\n",
    "OUTPUT_DIR = '/app/output'\n",
    "DATA_DIR = '/app/data/mimic-iv-2.0/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "patients_file = os.path.join(DATA_DIR, 'hosp', 'patients.csv.gz')\n",
    "admissions_file = os.path.join(DATA_DIR, 'hosp', 'admissions.csv.gz')\n",
    "lab_file = os.path.join(DATA_DIR, 'hosp', 'labevents.csv.gz')\n",
    "lab_meta_file = os.path.join(DATA_DIR, 'hosp', 'd_labitems.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "patients_df = pd.read_csv(patients_file, compression='gzip')\n",
    "patients_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "COLUMNS_TO_DROP = ['dod']\n",
    "patients_df.drop(COLUMNS_TO_DROP, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(len(patients_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "patients_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1,1,dpi=100)\n",
    "# tmp = patients_df[[AGE_COL, GENDER_COL]]\n",
    "# tmp[AGE_COL] = pd.cut(tmp[AGE_COL], bins=AGE_BINS, labels=AGE_LABELS)\n",
    "# tmp.groupby([AGE_COL, GENDER_COL]).size().unstack().plot(kind='bar', ax=ax)\n",
    "# ax.set_xlabel('Anchor Age [years]', fontsize=font_sz)\n",
    "# ax.set_ylabel('Number of Patients', fontsize=font_sz)\n",
    "# ax.set_title(f'Total Population, N={len(tmp)}', fontsize=font_sz)\n",
    "# ax.legend(labels=['Female', 'Male'], title=\"Sex\")\n",
    "# ax.set_xticklabels(AGE_LABELS, rotation=90)\n",
    "# fig.savefig(os.path.join(OUTPUT_DIR, 'age_gender_total.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1,1,dpi=100)\n",
    "# patients_df[YEAR_GROUP_COL].value_counts().plot.bar(ax=ax)\n",
    "# ax.set_ylabel('Number of Patients', fontsize=font_sz)\n",
    "# ax.set_xlabel('Anchor Year Group', fontsize=font_sz)\n",
    "# for p in ax.patches:\n",
    "#     ax.annotate(str(p.get_height()), (p.get_x(), p.get_height() * 1.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "admissions_df = pd.read_csv(admissions_file, compression='gzip', parse_dates=[ADMISSION_TIME_COL,\n",
    "                            DISCHARGE_TIME_COL, DEATH_TIME_COL, ED_REG_TIME, ED_OUT_TIME])\n",
    "admissions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "COLUMNS_TO_DROP = ['hospital_expire_flag', 'edouttime', 'edregtime', 'deathtime', 'language']\n",
    "admissions_df.drop(COLUMNS_TO_DROP, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "admissions_df = admissions_df.merge(patients_df, on=[SUBJECT_ID_COL])\n",
    "admissions_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Calculate Age at Admission and Group of Admission Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Based on mimic IV example https://mimic.mit.edu/docs/iv/modules/hosp/patients/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Diff column first\n",
    "admissions_df[ADMISSION_YEAR_COL] = (admissions_df[ADMISSION_TIME_COL].dt.year - admissions_df['anchor_year'])\n",
    "\n",
    "# Age at admission calculation\n",
    "admissions_df[ADMISSION_AGE_COL] = (admissions_df[AGE_COL] + admissions_df[ADMISSION_YEAR_COL])\n",
    "\n",
    "# Admission year group lower bound calculation\n",
    "admissions_df[ADMISSION_YEAR_COL] = admissions_df[ADMISSION_YEAR_COL] + admissions_df[YEAR_GROUP_COL].apply(lambda x: int(x.split(' ')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,dpi=100)\n",
    "admissions_df[ADMISSION_YEAR_COL].value_counts().sort_index().plot.bar(ax=ax)\n",
    "ax.set_ylabel('Number of Patients', fontsize=font_sz)\n",
    "ax.set_xlabel('Admission Year (lower bound)', fontsize=font_sz)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x(), p.get_height() * 1.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(8,4))\n",
    "tmp = admissions_df[[ADMISSION_AGE_COL, GENDER_COL]]\n",
    "tmp.groupby([ADMISSION_AGE_COL, GENDER_COL]).size().unstack().plot(kind='bar', ax=ax)\n",
    "ax.set_xlabel('Age at Admission [years]', fontsize=font_sz)\n",
    "ax.set_ylabel('Number of Patients', fontsize=font_sz)\n",
    "ax.set_title(f'Total Population, N={len(tmp)}', fontsize=font_sz)\n",
    "ax.legend(labels=['Female', 'Male'], title=\"Sex\")\n",
    "#ax.set_xticklabels(AGE_LABELS, rotation=90)\n",
    "plt.setp(ax.get_xticklabels()[1::2], visible=False)\n",
    "plt.show()\n",
    "#fig.savefig(os.path.join(OUTPUT_DIR, 'age_gender_admissions_total.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Calculating LOS (exact, days resolution) and night admission indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NIGHT_ADMISSION_FLAG = 'night_admission' \n",
    "\n",
    "admissions_df[LOS_EXACT_COL] = (admissions_df[DISCHARGE_TIME_COL] - admissions_df[ADMISSION_TIME_COL])\n",
    "admissions_df[NIGHT_ADMISSION_FLAG] = ((admissions_df[ADMISSION_TIME_COL].dt.hour >= 20) | \\\n",
    "                                       (admissions_df[ADMISSION_TIME_COL].dt.hour < 8) ).values\n",
    "admissions_df[LOS_DAYS_COL] = admissions_df[LOS_EXACT_COL].dt.ceil('1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "admissions_df[NIGHT_ADMISSION_FLAG].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,dpi=100)\n",
    "admissions_df[ADMISSION_TYPE_COL].value_counts().plot.bar(ax=ax)\n",
    "ax.set_ylabel('Number of Patients', fontsize=font_sz)\n",
    "ax.set_xlabel('Admission Type', fontsize=font_sz)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x(), p.get_height() * 1.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_clip_days = 30\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "ax = axes[0]\n",
    "tmp = admissions_df[admissions_df[ADMISSION_TYPE_COL] == 'URGENT']\n",
    "los_bar = tmp[LOS_DAYS_COL].clip(pd.to_timedelta('1d'), pd.to_timedelta(f'{max_clip_days}d')).value_counts().sort_index()\n",
    "los_bar.index = np.arange(1, max_clip_days+1)\n",
    "los_bar.plot.bar(ax=ax)\n",
    "ax.set_ylabel('Number of Patients', fontsize=font_sz)\n",
    "ax.set_xlabel('LOS (Days)', fontsize=font_sz)\n",
    "ax.grid(axis='y')\n",
    "ax.set_title('URGENT', fontsize=font_sz)\n",
    "\n",
    "ax = axes[1]\n",
    "tmp = admissions_df[admissions_df[ADMISSION_TYPE_COL] == 'EW EMER.']\n",
    "los_bar = tmp[LOS_DAYS_COL].clip(pd.to_timedelta('1d'), pd.to_timedelta(f'{max_clip_days}d')).value_counts().sort_index()\n",
    "los_bar.index = np.arange(1, max_clip_days+1)\n",
    "los_bar.plot.bar(ax=ax)\n",
    "ax.set_ylabel('Number of Patients', fontsize=font_sz)\n",
    "ax.set_xlabel('LOS (Days)', fontsize=font_sz)\n",
    "ax.grid(axis='y')\n",
    "ax.set_title('EW EMER.', fontsize=font_sz)\n",
    "\n",
    "ax = axes[2]\n",
    "tmp = admissions_df[admissions_df[ADMISSION_TYPE_COL] == 'DIRECT EMER.']\n",
    "los_bar = tmp[LOS_DAYS_COL].clip(pd.to_timedelta('1d'), pd.to_timedelta(f'{max_clip_days}d')).value_counts().sort_index()\n",
    "los_bar.index = np.arange(1, max_clip_days+1)\n",
    "los_bar.plot.bar(ax=ax)\n",
    "ax.set_ylabel('Number of Patients', fontsize=font_sz)\n",
    "ax.set_xlabel('LOS (Days)', fontsize=font_sz)\n",
    "ax.grid(axis='y')\n",
    "ax.set_title('DIRECT EMER.', fontsize=font_sz)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Taking only SPECIFIC_ADMISSION_TYPE admissions from now on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#SPECIFIC_ADMISSION_TYPE = ['URGENT']\n",
    "SPECIFIC_ADMISSION_TYPE = ['DIRECT EMER.', 'EW EMER.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(len(admissions_df))\n",
    "admissions_df = admissions_df[admissions_df[ADMISSION_TYPE_COL].isin(SPECIFIC_ADMISSION_TYPE)]\n",
    "print(len(admissions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# add direct emergency if needed\n",
    "DIRECT_IND_COL = 'direct_emrgency_flag'\n",
    "\n",
    "if 'DIRECT EMER.' in SPECIFIC_ADMISSION_TYPE:\n",
    "    admissions_df[DIRECT_IND_COL] = (admissions_df[ADMISSION_TYPE_COL] == 'DIRECT EMER.').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Counting SPECIFIC_ADMISSION_TYPE admissions to each patient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "number_of_admissions = admissions_df.groupby(SUBJECT_ID_COL)[ADMISSION_ID_COL].nunique()\n",
    "number_of_admissions.name = ADMISSION_COUNT_COL\n",
    "number_of_admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,dpi=100)\n",
    "number_of_admissions.value_counts().sort_index().plot.bar(ax=ax, logy=True)\n",
    "ax.set_ylabel('Number of Patients', fontsize=font_sz)\n",
    "ax.set_xlabel('Number of Admissions', fontsize=font_sz)\n",
    "ax.grid('y', which='minor', alpha=0.4)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x(), p.get_height() * 1.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "admissions_df = admissions_df.merge(number_of_admissions, on=SUBJECT_ID_COL)\n",
    "admissions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Add recurrent admissions group per patient according to last admission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ADMISSION_COUNT_GROUP_COL = ADMISSION_COUNT_COL + '_group'\n",
    "\n",
    "ADMISSION_COUNT_BINS = [1, 1.5, 2.5, 5000]\n",
    "ADMISSION_COUNT_LABELS = ['1', '2', '3up']\n",
    "\n",
    "admissions_df[ADMISSION_COUNT_GROUP_COL] = pd.cut(admissions_df[ADMISSION_COUNT_COL], \n",
    "                                                  bins=ADMISSION_COUNT_BINS, \n",
    "                                                  labels=ADMISSION_COUNT_LABELS, \n",
    "                                                  include_lowest=True)\n",
    "admissions_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Adds last admission with previous admission in past month indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PREV_ADMISSION_IND_COL = 'last_less_than_diff'\n",
    "indicator_diff = pd.to_timedelta('30d')\n",
    "\n",
    "tmp_admissions = admissions_df[admissions_df[ADMISSION_COUNT_COL] > 1]\n",
    "print(tmp_admissions.shape)\n",
    "ind_ser = tmp_admissions.sort_values(by=[SUBJECT_ID_COL, ADMISSION_TIME_COL]).groupby(\n",
    "    SUBJECT_ID_COL).apply(\n",
    "    lambda tmp_df: (tmp_df[ADMISSION_TIME_COL] - tmp_df[DISCHARGE_TIME_COL].shift(1)) <= indicator_diff)\n",
    "\n",
    "ind_ser.index = ind_ser.index.droplevel(1)\n",
    "ind_ser.name = PREV_ADMISSION_IND_COL\n",
    "ind_ser = ind_ser.iloc[ind_ser.reset_index().drop_duplicates(subset=[SUBJECT_ID_COL], keep='last').index]\n",
    "ind_ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "admissions_df = admissions_df.merge(ind_ser.astype(int), left_on=SUBJECT_ID_COL, right_index=True, how='outer')\n",
    "admissions_df[PREV_ADMISSION_IND_COL].fillna(0, inplace=True)\n",
    "admissions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Example\n",
    "admissions_df[admissions_df[PREV_ADMISSION_IND_COL] == 1].sort_values(by=[SUBJECT_ID_COL, ADMISSION_TIME_COL])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Keep only last admission per patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "only_last_admission = admissions_df.sort_values(by=[ADMISSION_TIME_COL]).drop_duplicates(subset=[SUBJECT_ID_COL], keep='last')\n",
    "len(only_last_admission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Take only patients with last admission after MINIMUM YEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# MINIMUM_YEAR = 2017\n",
    "MINIMUM_YEAR = 2014\n",
    "print(len(only_last_admission))\n",
    "only_last_admission = only_last_admission[only_last_admission[ADMISSION_YEAR_COL] >= MINIMUM_YEAR]\n",
    "print(len(only_last_admission))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "only_last_admission[PREV_ADMISSION_IND_COL].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pids = only_last_admission[SUBJECT_ID_COL].drop_duplicates()\n",
    "adm_ids = only_last_admission[ADMISSION_ID_COL].drop_duplicates()\n",
    "print(len(pids))\n",
    "print(len(adm_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load relevant lab tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LOAD_SPECIFIC_COLUMNS = [SUBJECT_ID_COL, ADMISSION_ID_COL, ITEM_ID_COL, 'storetime', 'flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "chunksize = 10 ** 6\n",
    "full_df = pd.DataFrame()\n",
    "with pd.read_csv(lab_file, chunksize=chunksize, compression='gzip', parse_dates=[STORE_TIME_COL], usecols=LOAD_SPECIFIC_COLUMNS) as reader:\n",
    "    for chunk in reader:\n",
    "        tmp_chunk = chunk[chunk[SUBJECT_ID_COL].isin(pids) & chunk[ADMISSION_ID_COL].isin(adm_ids)]\n",
    "        tmp_adms = only_last_admission[only_last_admission[SUBJECT_ID_COL].isin(pids) & only_last_admission[ADMISSION_ID_COL].isin(adm_ids)]\n",
    "        #tmp_patinets = patients_df[patients_df[SUBJECT_ID_COL].isin(pids)]\n",
    "        tmp_chunk = tmp_chunk.merge(tmp_adms, on=[SUBJECT_ID_COL, ADMISSION_ID_COL])\n",
    "        #tmp = tmp_chunk.merge(tmp_patinets, on=[SUBJECT_ID_COL])\n",
    "        full_df = pd.concat([full_df, tmp_chunk])\n",
    "        print(len(full_df))\n",
    "\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Continue only with included patients_df and admissions_df and full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pids = full_df[SUBJECT_ID_COL].drop_duplicates().values\n",
    "adms_ids = full_df[ADMISSION_ID_COL].drop_duplicates().values\n",
    "print(len(patients_df))\n",
    "patients_df = patients_df[patients_df[SUBJECT_ID_COL].isin(pids)]\n",
    "print(len(patients_df))\n",
    "print(len(admissions_df))\n",
    "admissions_df = admissions_df[admissions_df[ADMISSION_ID_COL].isin(adms_ids)]\n",
    "print(len(admissions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,dpi=100)\n",
    "admissions_df[ADMISSION_LOCATION_COL].value_counts().plot.bar(ax=ax)\n",
    "ax.set_ylabel('Number of Patients', fontsize=font_sz)\n",
    "ax.set_xlabel('Admission Location', fontsize=font_sz)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x(), p.get_height() * 1.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,dpi=100)\n",
    "admissions_df[DISCHARGE_LOCATION_COL].value_counts().plot.bar(ax=ax)\n",
    "ax.set_ylabel('Number of Patients', fontsize=font_sz)\n",
    "ax.set_xlabel('Discharge Location', fontsize=font_sz)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x(), p.get_height() * 1.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Regrouping discharge location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DISCHARGE_REGROUPING_DICT = {\n",
    "    'HOME': 'HOME',\n",
    "    'HOME HEALTH CARE': 'HOME',\n",
    "    'SKILLED NURSING FACILITY': 'FURTHER TREATMENT',\n",
    "    'DIED': 'DIED',\n",
    "    'REHAB': 'HOME',\n",
    "    'CHRONIC/LONG TERM ACUTE CARE': 'FURTHER TREATMENT',\n",
    "    'HOSPICE': 'FURTHER TREATMENT',\n",
    "    'AGAINST ADVICE': 'CENSORED',\n",
    "    'ACUTE HOSPITAL': 'FURTHER TREATMENT',\n",
    "    'PSYCH FACILITY': 'FURTHER TREATMENT',\n",
    "    'OTHER FACILITY': 'FURTHER TREATMENT',\n",
    "    'ASSISTED LIVING': 'HOME',\n",
    "    'HEALTHCARE FACILITY': 'FURTHER TREATMENT',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "admissions_df[DISCHARGE_LOCATION_COL].replace(DISCHARGE_REGROUPING_DICT, inplace=True)\n",
    "full_df[DISCHARGE_LOCATION_COL].replace(DISCHARGE_REGROUPING_DICT, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,dpi=100)\n",
    "admissions_df[DISCHARGE_LOCATION_COL].value_counts().plot.bar(ax=ax)\n",
    "ax.set_ylabel('Number of Patients', fontsize=font_sz)\n",
    "ax.set_xlabel('Discharge Location', fontsize=font_sz)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x(), p.get_height() * 1.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,dpi=100)\n",
    "tmp = admissions_df[[ADMISSION_AGE_COL, GENDER_COL]]\n",
    "#tmp[ADMISSION_AGE_COL] = pd.cut(tmp[ADMISSION_AGE_COL], bins=AGE_BINS, labels=AGE_LABELS)\n",
    "tmp.groupby([ADMISSION_AGE_COL, GENDER_COL]).size().unstack().plot(kind='bar', ax=ax)\n",
    "ax.set_xlabel('Age at Admission [years]', fontsize=font_sz)\n",
    "ax.set_ylabel('Number of Patients', fontsize=font_sz)\n",
    "ax.set_title(f'Total Population, N={len(tmp)}', fontsize=font_sz)\n",
    "ax.legend(labels=['Female', 'Male'], title=\"Sex\")\n",
    "plt.setp(ax.get_xticklabels()[1::2], visible=False)\n",
    "#ax.set_xticklabels(AGE_LABELS, rotation=90)\n",
    "fig.savefig(os.path.join(OUTPUT_DIR, 'age_gender_admissions_subset.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Regroup Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "RACE_REGROUPING_DICT = {\n",
    "    'WHITE': 'WHITE',\n",
    "    'UNKNOWN': 'OTHER',\n",
    "    'BLACK/AFRICAN AMERICAN': 'BLACK',\n",
    "    'OTHER': 'OTHER',\n",
    "    'ASIAN': 'ASIAN',\n",
    "    'WHITE - OTHER EUROPEAN': 'WHITE',\n",
    "    'HISPANIC/LATINO - PUERTO RICAN': 'HISPANIC',\n",
    "    'HISPANIC/LATINO - DOMINICAN': 'HISPANIC',\n",
    "    'ASIAN - CHINESE': 'ASIAN',\n",
    "    'BLACK/CARIBBEAN ISLAND': 'BLACK',\n",
    "    'BLACK/AFRICAN': 'BLACK',\n",
    "    'BLACK/CAPE VERDEAN': 'BLACK',\n",
    "    'PATIENT DECLINED TO ANSWER': 'OTHER',\n",
    "    'WHITE - BRAZILIAN': 'WHITE',\n",
    "    'PORTUGUESE': 'HISPANIC', \n",
    "    'ASIAN - SOUTH EAST ASIAN': 'ASIAN',\n",
    "    'WHITE - RUSSIAN': 'WHITE',\n",
    "    'ASIAN - ASIAN INDIAN': 'ASIAN',\n",
    "    'WHITE - EASTERN EUROPEAN': 'WHITE',\n",
    "    'AMERICAN INDIAN/ALASKA NATIVE': 'OTHER',\n",
    "    'HISPANIC/LATINO - GUATEMALAN': 'HISPANIC',\n",
    "    'HISPANIC/LATINO - MEXICAN': 'HISPANIC',\n",
    "    'HISPANIC/LATINO - SALVADORAN': 'HISPANIC',\n",
    "    'SOUTH AMERICAN': 'HISPANIC',\n",
    "    'NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER': 'OTHER',\n",
    "    'HISPANIC/LATINO - COLUMBIAN': 'HISPANIC',\n",
    "    'HISPANIC/LATINO - CUBAN': 'HISPANIC',\n",
    "    'ASIAN - KOREAN': 'ASIAN',\n",
    "    'HISPANIC/LATINO - HONDURAN': 'HISPANIC',\n",
    "    'HISPANIC/LATINO - CENTRAL AMERICAN': 'HISPANIC',\n",
    "    'UNABLE TO OBTAIN': 'OTHER',\n",
    "    'HISPANIC OR LATINO': 'HISPANIC'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "admissions_df[RACE_COL].replace(RACE_REGROUPING_DICT, inplace=True)\n",
    "full_df[RACE_COL].replace(RACE_REGROUPING_DICT, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,dpi=100)\n",
    "admissions_df[RACE_COL].value_counts().plot.bar(ax=ax)\n",
    "ax.set_ylabel('Number of Patients', fontsize=font_sz)\n",
    "ax.set_xlabel('Race', fontsize=font_sz)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x(), p.get_height() * 1.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,dpi=100)\n",
    "admissions_df[INSURANCE_COL].value_counts().plot.bar(ax=ax)\n",
    "ax.set_ylabel('Number of Patients', fontsize=font_sz)\n",
    "ax.set_xlabel('Insurance', fontsize=font_sz)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x(), p.get_height() * 1.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Taking only results 24 hours from admission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "full_df[ADMISSION_TO_RESULT_COL] = (full_df[STORE_TIME_COL] - full_df[ADMISSION_TIME_COL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(len(full_df[ADMISSION_TO_RESULT_COL]))\n",
    "print(len(full_df[full_df[ADMISSION_TO_RESULT_COL] <= pd.to_timedelta('1d')]))\n",
    "print(len(full_df[full_df[ADMISSION_TO_RESULT_COL] <= pd.to_timedelta('2d')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(len(full_df[ADMISSION_ID_COL].drop_duplicates()))\n",
    "print(len(full_df[full_df[ADMISSION_TO_RESULT_COL] <= pd.to_timedelta('1d')][ADMISSION_ID_COL].drop_duplicates()))\n",
    "print(len(full_df[full_df[ADMISSION_TO_RESULT_COL] <= pd.to_timedelta('2d')][ADMISSION_ID_COL].drop_duplicates()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "full_df = full_df[full_df[ADMISSION_TO_RESULT_COL] <= pd.to_timedelta('1d')]\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(len(full_df))\n",
    "full_df.sort_values(by=[ADMISSION_TIME_COL, STORE_TIME_COL]).drop_duplicates(subset=[SUBJECT_ID_COL, ADMISSION_ID_COL, ITEM_ID_COL], \n",
    "    inplace=True, keep='last')\n",
    "print(len(full_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Most common lab tests upon arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lab_meta_df = pd.read_csv(lab_meta_file, compression='gzip')\n",
    "lab_meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "threshold = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "common_tests = full_df.groupby(ITEM_ID_COL)[ADMISSION_ID_COL].nunique().sort_values(ascending=False)\n",
    "included_in_threshold = common_tests[common_tests > threshold].to_frame().merge(lab_meta_df, on=ITEM_ID_COL)\n",
    "included_in_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(len(full_df))\n",
    "full_df = full_df[full_df[ITEM_ID_COL].isin(included_in_threshold[ITEM_ID_COL].values)]\n",
    "print(len(full_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "minimal_item_id = included_in_threshold.iloc[-1][ITEM_ID_COL]\n",
    "minimal_item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pids = full_df[full_df[ITEM_ID_COL] == minimal_item_id][SUBJECT_ID_COL].drop_duplicates().values\n",
    "adms_ids = full_df[full_df[ITEM_ID_COL] == minimal_item_id][ADMISSION_ID_COL].drop_duplicates().values\n",
    "print(len(patients_df))\n",
    "patients_df = patients_df[patients_df[SUBJECT_ID_COL].isin(pids)]\n",
    "print(len(patients_df))\n",
    "print(len(admissions_df))\n",
    "admissions_df = admissions_df[admissions_df[ADMISSION_ID_COL].isin(adms_ids)]\n",
    "print(len(admissions_df))\n",
    "print(len(admissions_df))\n",
    "full_df = full_df[full_df[SUBJECT_ID_COL].isin(pids)]\n",
    "full_df = full_df[full_df[ADMISSION_ID_COL].isin(adms_ids)]\n",
    "print(len(admissions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "full_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "full_df['flag'].fillna('normal', inplace=True)\n",
    "full_df['flag'].replace({'normal': 0, 'abnormal':1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "full_df['flag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "full_df = full_df.sort_values(by=[ADMISSION_TIME_COL, STORE_TIME_COL]).drop_duplicates(\n",
    "    subset=[SUBJECT_ID_COL, ADMISSION_ID_COL, ITEM_ID_COL], \n",
    "    keep='last')\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp = full_df[[SUBJECT_ID_COL, ADMISSION_ID_COL, ITEM_ID_COL, 'flag']]\n",
    "fitters_table = pd.pivot_table(tmp, values=['flag'], index=[SUBJECT_ID_COL, ADMISSION_ID_COL], \n",
    "                               columns=[ITEM_ID_COL], aggfunc=np.sum)\n",
    "fitters_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fitters_table = fitters_table.droplevel(1, axis=0).droplevel(0, axis=1)\n",
    "fitters_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MARITAL_STATUS_COL = 'marital_status'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "full_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dummies_df = full_df.drop_duplicates(subset=[SUBJECT_ID_COL]).set_index(SUBJECT_ID_COL)\n",
    "dummies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(dummies_df[INSURANCE_COL], prefix='Insurance', drop_first=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dummies_df[NIGHT_ADMISSION_FLAG].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "del full_df\n",
    "del admissions_df\n",
    "del patients_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dummies_df[GENDER_COL].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Standardize age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "STANDARDIZED_AGE_COL = 'standardized_age'\n",
    "scaler = StandardScaler()\n",
    "dummies_df[STANDARDIZED_AGE_COL] = scaler.fit_transform(dummies_df[[AGE_COL]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "J_DICT = {'HOME': 1, 'FURTHER TREATMENT': 2, 'DIED': 3, 'CENSORED': 0} \n",
    "GENDER_DICT = {'F': 1, 'M': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dummies_df[GENDER_COL] = dummies_df[GENDER_COL].replace(GENDER_DICT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tableone import TableOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "included_in_threshold['label'] = included_in_threshold['label'].apply(lambda x: x.replace(' ', '')).apply(lambda x: x.replace(',', ''))\n",
    "RENAME_ITEMS_DICT = included_in_threshold[[ITEM_ID_COL, 'label']].set_index(ITEM_ID_COL).to_dict()['label']\n",
    "RENAME_ITEMS_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "table1 = pd.concat([\n",
    "    fitters_table,\n",
    "    #pd.get_dummies(dummies_df[INSURANCE_COL], prefix='Insurance'),\n",
    "    #pd.get_dummies(dummies_df[MARITAL_STATUS_COL], prefix='Marital'),\n",
    "    #pd.get_dummies(dummies_df[RACE_COL], prefix='Ethnicity'),\n",
    "    #pd.get_dummies(dummies_df[ADMISSION_COUNT_GROUP_COL], prefix='AdmsCount'),\n",
    "    dummies_df[[NIGHT_ADMISSION_FLAG,\n",
    "                GENDER_COL, \n",
    "                DIRECT_IND_COL,\n",
    "                PREV_ADMISSION_IND_COL,\n",
    "                ADMISSION_AGE_COL]].astype(int),\n",
    "    dummies_df[[INSURANCE_COL,\n",
    "                MARITAL_STATUS_COL,\n",
    "                RACE_COL,\n",
    "                ADMISSION_COUNT_GROUP_COL]],\n",
    "    dummies_df[LOS_DAYS_COL].dt.days,\n",
    "    dummies_df[DISCHARGE_LOCATION_COL].dropna().replace(J_DICT).astype(int)\n",
    "], axis=1)\n",
    "    \n",
    "table1.rename(RENAME_ITEMS_DICT, inplace=True, axis=1)  \n",
    "table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "table1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "columns = ['gender', 'admission_age', 'race', 'insurance', 'marital_status',\n",
    "           'direct_emrgency_flag', 'night_admission', 'last_less_than_diff', \n",
    "           'admissions_count_group', 'LOS days', 'discharge_location']\n",
    "categorical = ['gender', 'race', 'insurance', 'marital_status',\n",
    "           'direct_emrgency_flag', 'night_admission', 'last_less_than_diff', \n",
    "           'admissions_count_group', 'discharge_location']\n",
    "\n",
    "groupby = [GENDER_COL]\n",
    "mytable = TableOne(table1.dropna(), columns, categorical, groupby)\n",
    "mytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(mytable.tableone.round(3).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "columns = ['gender', 'AnionGap', 'Bicarbonate', 'CalciumTotal', 'Chloride', 'Creatinine',\n",
    "           'Glucose', 'Magnesium', 'Phosphate', 'Potassium', 'Sodium',\n",
    "           'UreaNitrogen', 'Hematocrit', 'Hemoglobin', 'MCH', 'MCHC', 'MCV',\n",
    "           'PlateletCount', 'RDW', 'RedBloodCells', 'WhiteBloodCells']\n",
    "categorical = ['gender', 'AnionGap', 'Bicarbonate', 'CalciumTotal', 'Chloride', 'Creatinine',\n",
    "           'Glucose', 'Magnesium', 'Phosphate', 'Potassium', 'Sodium',\n",
    "           'UreaNitrogen', 'Hematocrit', 'Hemoglobin', 'MCH', 'MCHC', 'MCV',\n",
    "           'PlateletCount', 'RDW', 'RedBloodCells', 'WhiteBloodCells']\n",
    "\n",
    "groupby = [GENDER_COL]\n",
    "mytable = TableOne(table1.dropna(), columns, categorical, groupby)\n",
    "mytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(mytable.tableone.round(3).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fitters_table = pd.concat([\n",
    "    fitters_table,\n",
    "    pd.get_dummies(dummies_df[INSURANCE_COL], prefix='Insurance', drop_first=True),\n",
    "    pd.get_dummies(dummies_df[MARITAL_STATUS_COL], prefix='Marital', drop_first=True),\n",
    "    pd.get_dummies(dummies_df[RACE_COL], prefix='Ethnicity', drop_first=True),\n",
    "    pd.get_dummies(dummies_df[ADMISSION_COUNT_GROUP_COL], prefix='AdmsCount', drop_first=True),\n",
    "    dummies_df[[NIGHT_ADMISSION_FLAG, \n",
    "                GENDER_COL, \n",
    "                DIRECT_IND_COL,\n",
    "                PREV_ADMISSION_IND_COL]].astype(int),\n",
    "    dummies_df[STANDARDIZED_AGE_COL],\n",
    "    dummies_df[LOS_DAYS_COL].dt.days,\n",
    "    dummies_df[DISCHARGE_LOCATION_COL].dropna().replace(J_DICT).astype(int)\n",
    "], axis=1)\n",
    "    \n",
    "fitters_table   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(len(fitters_table))\n",
    "fitters_table.dropna(inplace=True)\n",
    "print(len(fitters_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fitters_table.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fitters_table.rename({DISCHARGE_LOCATION_COL: 'J', LOS_DAYS_COL: 'X', SUBJECT_ID_COL: 'pid'}, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fitters_table.rename(RENAME_ITEMS_DICT, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ADMINISTRATIVE_CENSORING = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fitters_table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fitters_table = fitters_table[fitters_table['X'] > 0]\n",
    "fitters_table.loc[fitters_table.X > ADMINISTRATIVE_CENSORING, 'J'] = 0\n",
    "fitters_table.loc[fitters_table.X > ADMINISTRATIVE_CENSORING, 'X'] = ADMINISTRATIVE_CENSORING + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fitters_table['J'] = fitters_table['J'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fitters_table.groupby(['X', 'J'])['pid'].count().sort_index().tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pydts.examples_utils.plots import plot_example_pred_output\n",
    "from pydts.examples_utils.plots import add_panel_text\n",
    "from pydts.fitters import TwoStagesFitter, DataExpansionFitter\n",
    "from pydts.examples_utils.plots import plot_events_occurrence\n",
    "\n",
    "from time import time\n",
    "\n",
    "slicer = pd.IndexSlice\n",
    "\n",
    "plot_events_occurrence(fitters_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "COEF_COL = '   coef   '\n",
    "STDERR_COL = ' std err '\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "case = f'mimic_final_'\n",
    "two_step_timing = []\n",
    "lee_timing = []\n",
    "\n",
    "# Two step fitter\n",
    "new_fitter = TwoStagesFitter()\n",
    "print(f'Starting two-step')\n",
    "two_step_start = time()\n",
    "new_fitter.fit(df=fitters_table, nb_workers=1)\n",
    "two_step_end = time()\n",
    "print(f'Finished two-step: {two_step_end-two_step_start}sec')\n",
    "\n",
    "two_step_timing.append(two_step_end-two_step_start)\n",
    "\n",
    "# Lee et al fitter\n",
    "print(f'Starting Lee et al.')\n",
    "lee_fitter = DataExpansionFitter()\n",
    "lee_start = time()\n",
    "lee_fitter.fit(df=fitters_table)\n",
    "lee_end = time()\n",
    "print(f'Finished lee: {lee_end-lee_start}sec')\n",
    "\n",
    "lee_timing.append(lee_end-lee_start) \n",
    "\n",
    "lee_alpha_ser = lee_fitter.get_alpha_df().loc[:, slicer[:, [COEF_COL, STDERR_COL] ]].unstack().sort_index()\n",
    "lee_beta_ser = lee_fitter.get_beta_SE().loc[:, slicer[:, [COEF_COL, STDERR_COL] ]].unstack().sort_index()\n",
    "\n",
    "two_step_alpha_k_results = new_fitter.alpha_df[['J', 'X', 'alpha_jt']]\n",
    "two_step_beta_k_results = new_fitter.get_beta_SE().unstack().to_frame()\n",
    "\n",
    "lee_alpha_k_results = lee_alpha_ser.to_frame()\n",
    "lee_beta_k_results = lee_beta_ser.to_frame()\n",
    "\n",
    "# Cache results\n",
    "two_step_alpha_k_results.to_csv(os.path.join(OUTPUT_DIR, f'{case}_two_step_alpha.csv'))\n",
    "two_step_beta_k_results.to_csv(os.path.join(OUTPUT_DIR, f'{case}_two_step_beta.csv'))\n",
    "lee_alpha_k_results.to_csv(os.path.join(OUTPUT_DIR, f'{case}_lee_alpha.csv'))\n",
    "lee_beta_k_results.to_csv(os.path.join(OUTPUT_DIR, f'{case}_lee_beta.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "covariates = [c for c in fitters_table.columns if c not in ['pid', 'J', 'X']]\n",
    "covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "two_step_alpha_k_results = pd.read_csv(os.path.join(OUTPUT_DIR, f'{case}_two_step_alpha.csv'), \n",
    "                                       index_col=['J', 'X'])\n",
    "two_step_beta_k_results = pd.read_csv(os.path.join(OUTPUT_DIR, f'{case}_two_step_beta.csv'),\n",
    "                                      index_col=[0, 1])\n",
    "lee_alpha_k_results = pd.read_csv(os.path.join(OUTPUT_DIR, f'{case}_lee_alpha.csv'),\n",
    "                                  index_col=[0,1,2])\n",
    "lee_beta_k_results = pd.read_csv(os.path.join(OUTPUT_DIR, f'{case}_lee_beta.csv'),\n",
    "                                 index_col=[0, 1, 2])\n",
    "\n",
    "\n",
    "twostep_beta1_summary = two_step_beta_k_results.mean(axis=1).unstack([0]).round(3).iloc[:, [1,0]]\n",
    "twostep_beta1_summary.index = [f'{iii.replace(\" \", \"\")}_1' for iii in twostep_beta1_summary.index]\n",
    "twostep_beta2_summary = two_step_beta_k_results.mean(axis=1).unstack([0]).round(3).iloc[:, [3,2]]\n",
    "twostep_beta2_summary.index = [f'{iii.replace(\" \", \"\")}_2' for iii in twostep_beta2_summary.index]\n",
    "twostep_beta3_summary = two_step_beta_k_results.mean(axis=1).unstack([0]).round(3).iloc[:, [5,4]]\n",
    "twostep_beta3_summary.index = [f'{iii.replace(\" \", \"\")}_3' for iii in twostep_beta3_summary.index]\n",
    "\n",
    "lee_beta1_summary = lee_beta_k_results.mean(axis=1).loc[slicer[1,:,:]].unstack([0]).round(3)\n",
    "lee_beta1_summary.index = [f'{iii.replace(\" \", \"\")}_1' for iii in lee_beta1_summary.index]\n",
    "lee_beta2_summary = lee_beta_k_results.mean(axis=1).loc[slicer[2,:,:]].unstack([0]).round(3)\n",
    "lee_beta2_summary.index = [f'{iii.replace(\" \", \"\")}_2' for iii in lee_beta2_summary.index]\n",
    "lee_beta3_summary = lee_beta_k_results.mean(axis=1).loc[slicer[3,:,:]].unstack([0]).round(3)\n",
    "lee_beta3_summary.index = [f'{iii.replace(\" \", \"\")}_3' for iii in lee_beta3_summary.index]\n",
    "    \n",
    "lee_beta1_summary.columns = pd.MultiIndex.from_tuples([('Lee et al.', 'Estimate'), ('Lee et al.', 'Estimated SE')])\n",
    "lee_beta2_summary.columns = pd.MultiIndex.from_tuples([('Lee et al.', 'Estimate'), ('Lee et al.', 'Estimated SE')])\n",
    "lee_beta3_summary.columns = pd.MultiIndex.from_tuples([('Lee et al.', 'Estimate'), ('Lee et al.', 'Estimated SE')])\n",
    "\n",
    "beta_summary_comparison = pd.concat([lee_beta1_summary, lee_beta2_summary, lee_beta3_summary], axis=0)\n",
    "#beta_summary_comparison.index = [r'$\\beta_{11}$', r'$\\beta_{12}$', r'$\\beta_{13}$', r'$\\beta_{14}$', r'$\\beta_{15}$',\n",
    "#                                 r'$\\beta_{21}$', r'$\\beta_{22}$', r'$\\beta_{23}$', r'$\\beta_{24}$', r'$\\beta_{25}$',\n",
    "#                                 r'$\\beta_{31}$', r'$\\beta_{32}$', r'$\\beta_{33}$', r'$\\beta_{34}$', r'$\\beta_{35}$']\n",
    "twostep_beta1_summary.columns = pd.MultiIndex.from_tuples([('two-step', 'Estimate'), ('two-step', 'Estimated SE')])\n",
    "twostep_beta2_summary.columns = pd.MultiIndex.from_tuples([('two-step', 'Estimate'), ('two-step', 'Estimated SE')])\n",
    "twostep_beta3_summary.columns = pd.MultiIndex.from_tuples([('two-step', 'Estimate'), ('two-step', 'Estimated SE')])\n",
    "\n",
    "tmp = pd.concat([twostep_beta1_summary.round(3), twostep_beta2_summary.round(3), twostep_beta3_summary.round(3)], axis=0)\n",
    "#tmp.index = [r'$\\beta_{11}$', r'$\\beta_{12}$', r'$\\beta_{13}$', r'$\\beta_{14}$', r'$\\beta_{15}$',\n",
    "#             r'$\\beta_{21}$', r'$\\beta_{22}$', r'$\\beta_{23}$', r'$\\beta_{24}$', r'$\\beta_{25}$',\n",
    "#             r'$\\beta_{31}$', r'$\\beta_{32}$', r'$\\beta_{33}$', r'$\\beta_{34}$', r'$\\beta_{35}$']\n",
    "\n",
    "\n",
    "beta_summary_comparison = pd.concat([beta_summary_comparison, tmp], axis=1)\n",
    "beta_summary_comparison.index.name =  r'$\\beta_{jk}$'\n",
    "beta_summary_comparison.index = [c.replace(\"_\", \" \") for c in beta_summary_comparison.index]\n",
    "beta_summary_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(beta_summary_comparison.to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'mimic_summary_.png'\n",
    "\n",
    "first_model_name = 'Lee et al.'\n",
    "second_model_name = 'two-step'\n",
    "times = range(1, ADMINISTRATIVE_CENSORING+1)\n",
    "\n",
    "lee_colors = ['tab:blue', 'tab:green', 'tab:red']\n",
    "two_step_colors = ['navy', 'darkgreen', 'tab:brown']\n",
    "true_colors = ['tab:blue', 'tab:green', 'tab:red']\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "counts = fitters_table.groupby(['J', 'X'])['pid'].count().unstack('J').fillna(0)\n",
    "\n",
    "two_step_alpha_k_results = pd.read_csv(os.path.join(OUTPUT_DIR, f'{case}_two_step_alpha.csv'), \n",
    "                                         index_col=['J', 'X'])\n",
    "\n",
    "lee_alpha_k_results = pd.read_csv(os.path.join(OUTPUT_DIR, f'{case}_lee_alpha.csv'),\n",
    "                                   index_col=[0,1,2])\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "\n",
    "for j in [1, 2, 3]:\n",
    "\n",
    "    tmp_alpha = lee_alpha_k_results.loc[slicer[j, COEF_COL, :]].mean(axis=1)\n",
    "    tmp_alpha.index = [int(idx.split(')[')[1].split(']')[0]) for idx in tmp_alpha.index]\n",
    "    tmp_alpha = pd.Series(tmp_alpha.values.squeeze().astype(float), index=tmp_alpha.index)\n",
    "\n",
    "    ax.scatter(tmp_alpha.index, tmp_alpha.values,\n",
    "       label=f'J={j} ({first_model_name})', color=lee_colors[j-1], marker='o', alpha=0.4, s=40)\n",
    "\n",
    "    tmp_alpha = two_step_alpha_k_results.loc[slicer[j, 'alpha_jt']]\n",
    "    ax.scatter(tmp_alpha.index, tmp_alpha.values,\n",
    "       label=f'J={j} ({second_model_name})', color=two_step_colors[j-1], marker='*', alpha=0.7, s=20)\n",
    "\n",
    "    ax.set_xlabel(r'Time', fontsize=18)\n",
    "    ax.set_ylabel(r'$\\alpha_{jt}$', fontsize=18)\n",
    "    ax.legend(loc='upper right', fontsize=12)\n",
    "\n",
    "ax.set_ylim([-13, 3])\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.bar(counts.index, counts[1].values.squeeze(), label='J=1', color='navy', alpha=0.4, width=0.4)\n",
    "ax2.bar(counts.index, counts[2].values.squeeze(), label='J=2', color='darkgreen', alpha=0.4, align='edge',\n",
    "        width=0.4)\n",
    "ax2.bar(counts.index, counts[3].values.squeeze(), label='J=3', color='tab:red', alpha=0.6, align='edge',\n",
    "        width=-0.4)\n",
    "ax2.legend(loc='upper center', fontsize=12)\n",
    "ax2.set_ylabel('Number of observed events', fontsize=16, color='red')\n",
    "ax2.tick_params(axis='y', colors='red')\n",
    "ax2.set_ylim([0, 8000])\n",
    "ax2.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax2.tick_params(axis='both', which='minor', labelsize=15)\n",
    "    \n",
    "fig.tight_layout()\n",
    "\n",
    "if filename is not None:\n",
    "    fig.savefig(os.path.join(OUTPUT_DIR, filename), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "case = f'mimic_regularized_final_'\n",
    "two_step_timing = []\n",
    "lee_timing = []\n",
    "\n",
    "penalizer = 0\n",
    "\n",
    "fit_beta_kwargs = {\n",
    "    'model_kwargs': {\n",
    "        'penalizer': penalizer,\n",
    "        'l1_ratio': 1\n",
    "    }\n",
    "}\n",
    "\n",
    "# Two step fitter\n",
    "regularized_fitter = TwoStagesFitter()\n",
    "print(f'Starting two-step')\n",
    "two_step_start = time()\n",
    "regularized_fitter.fit(df=fitters_table, fit_beta_kwargs=fit_beta_kwargs, nb_workers=1)\n",
    "two_step_end = time()\n",
    "print(f'Finished two-step: {two_step_end-two_step_start}sec')\n",
    "\n",
    "two_step_timing.append(two_step_end-two_step_start)\n",
    "\n",
    "two_step_alpha_k_results = regularized_fitter.alpha_df[['J', 'X', 'alpha_jt']]\n",
    "two_step_beta_k_results = regularized_fitter.get_beta_SE().unstack().to_frame()\n",
    "\n",
    "two_step_alpha_k_results.to_csv(os.path.join(OUTPUT_DIR, f'{case}_two_step_alpha.csv'))\n",
    "two_step_beta_k_results.to_csv(os.path.join(OUTPUT_DIR, f'{case}_two_step_beta.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "two_step_alpha_k_results = pd.read_csv(os.path.join(OUTPUT_DIR, f'{case}_two_step_alpha.csv'), \n",
    "                                       index_col=['J', 'X'])\n",
    "two_step_beta_k_results = pd.read_csv(os.path.join(OUTPUT_DIR, f'{case}_two_step_beta.csv'),\n",
    "                                      index_col=[0, 1])\n",
    "\n",
    "twostep_beta1_summary = two_step_beta_k_results.mean(axis=1).unstack([0]).round(3).iloc[:, [1,0]]\n",
    "twostep_beta1_summary.index = [f'{iii.replace(\" \", \"\")}_1' for iii in twostep_beta1_summary.index]\n",
    "twostep_beta2_summary = two_step_beta_k_results.mean(axis=1).unstack([0]).round(3).iloc[:, [3,2]]\n",
    "twostep_beta2_summary.index = [f'{iii.replace(\" \", \"\")}_2' for iii in twostep_beta2_summary.index]\n",
    "twostep_beta3_summary = two_step_beta_k_results.mean(axis=1).unstack([0]).round(3).iloc[:, [5,4]]\n",
    "twostep_beta3_summary.index = [f'{iii.replace(\" \", \"\")}_3' for iii in twostep_beta3_summary.index]\n",
    "\n",
    "twostep_beta1_summary.columns = pd.MultiIndex.from_tuples([('two-step', 'Estimate'), ('two-step', 'Estimated SE')])\n",
    "twostep_beta2_summary.columns = pd.MultiIndex.from_tuples([('two-step', 'Estimate'), ('two-step', 'Estimated SE')])\n",
    "twostep_beta3_summary.columns = pd.MultiIndex.from_tuples([('two-step', 'Estimate'), ('two-step', 'Estimated SE')])\n",
    "\n",
    "tmp = pd.concat([twostep_beta1_summary.round(3), twostep_beta2_summary.round(3), twostep_beta3_summary.round(3)], \n",
    "                axis=0)\n",
    "\n",
    "beta_summary_comparison = pd.concat([beta_summary_comparison, tmp], axis=1)\n",
    "beta_summary_comparison.index.name =  r'$\\beta_{jk}$'\n",
    "beta_summary_comparison.index = [c.replace(\"_\", \" \") for c in beta_summary_comparison.index]\n",
    "beta_summary_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(beta_summary_comparison.to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'mimic_regularized_summary.png'\n",
    "\n",
    "first_model_name = 'Lee et al.'\n",
    "second_model_name = 'two-step'\n",
    "times = range(1, ADMINISTRATIVE_CENSORING+1)\n",
    "\n",
    "lee_colors = ['tab:blue', 'tab:green', 'tab:red']\n",
    "two_step_colors = ['navy', 'darkgreen', 'tab:brown']\n",
    "true_colors = ['tab:blue', 'tab:green', 'tab:red']\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "counts = fitters_table.groupby(['J', 'X'])['pid'].count().unstack('J').fillna(0)\n",
    "\n",
    "two_step_alpha_k_results = pd.read_csv(os.path.join(OUTPUT_DIR, f'{case}_two_step_alpha.csv'), \n",
    "                                         index_col=['J', 'X'])\n",
    "\n",
    "lee_alpha_k_results = pd.read_csv(os.path.join(OUTPUT_DIR, f'{case}_lee_alpha.csv'),\n",
    "                                   index_col=[0,1,2])\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "\n",
    "for j in [1, 2, 3]:\n",
    "\n",
    "    tmp_alpha = lee_alpha_k_results.loc[slicer[j, COEF_COL, :]].mean(axis=1)\n",
    "    tmp_alpha.index = [int(idx.split(')[')[1].split(']')[0]) for idx in tmp_alpha.index]\n",
    "    tmp_alpha = pd.Series(tmp_alpha.values.squeeze().astype(float), index=tmp_alpha.index)\n",
    "\n",
    "    ax.scatter(tmp_alpha.index, tmp_alpha.values,\n",
    "       label=f'J={j} ({first_model_name})', color=lee_colors[j-1], marker='o', alpha=0.4, s=40)\n",
    "\n",
    "    tmp_alpha = two_step_alpha_k_results.loc[slicer[j, 'alpha_jt']]\n",
    "    ax.scatter(tmp_alpha.index, tmp_alpha.values,\n",
    "       label=f'J={j} ({second_model_name})', color=two_step_colors[j-1], marker='*', alpha=0.7, s=20)\n",
    "\n",
    "    ax.set_xlabel(r'Time', fontsize=18)\n",
    "    ax.set_ylabel(r'$\\alpha_{jt}$', fontsize=18)\n",
    "    ax.legend(loc='upper right', fontsize=12)\n",
    "\n",
    "ax.set_ylim([-13, 3])\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.bar(counts.index, counts[1].values.squeeze(), label='J=1', color='navy', alpha=0.4, width=0.4)\n",
    "ax2.bar(counts.index, counts[2].values.squeeze(), label='J=2', color='darkgreen', alpha=0.4, align='edge',\n",
    "        width=0.4)\n",
    "ax2.bar(counts.index, counts[3].values.squeeze(), label='J=3', color='tab:red', alpha=0.6, align='edge',\n",
    "        width=-0.4)\n",
    "ax2.legend(loc='upper center', fontsize=12)\n",
    "ax2.set_ylabel('Number of observed events', fontsize=16, color='red')\n",
    "ax2.tick_params(axis='y', colors='red')\n",
    "ax2.set_ylim([0, 8000])\n",
    "ax2.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax2.tick_params(axis='both', which='minor', labelsize=15)\n",
    "    \n",
    "fig.tight_layout()\n",
    "\n",
    "if filename is not None:\n",
    "    fig.savefig(os.path.join(OUTPUT_DIR, filename), dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}