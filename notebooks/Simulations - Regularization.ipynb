{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pydts.examples_utils.generate_simulations_data import generate_quick_start_df\n",
    "from pydts.examples_utils.plots import plot_example_pred_output\n",
    "from pydts.examples_utils.plots import add_panel_text\n",
    "from pydts.cross_validation import TwoStagesCV\n",
    "from pydts.fitters import TwoStagesFitter, DataExpansionFitter\n",
    "\n",
    "from pydts.data_generation import EventTimesSampler\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "from sklearn.model_selection import KFold\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "slicer = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = '/home/tomer.me/DiscreteTimeSurvivalPenalization/output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Sampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cov = 100\n",
    "beta1 = np.zeros(n_cov)\n",
    "beta1[:5] = [1.2, 1.5, -1, -0.3, -1.2]\n",
    "beta2 = np.zeros(n_cov)\n",
    "beta2[:5] = [-1.2, 1, 1, -1, 1.4]\n",
    "\n",
    "\n",
    "real_coef_dict = {\n",
    "    \"alpha\": {\n",
    "        1: lambda t: -3.4 - 0.1 * np.log(t),\n",
    "        2: lambda t: -3.4 - 0.2 * np.log(t)\n",
    "    },\n",
    "    \"beta\": {\n",
    "        1: beta1,\n",
    "        2: beta2\n",
    "    }\n",
    "}\n",
    "\n",
    "n_patients = 10000\n",
    "d_times = 15\n",
    "j_events = 2\n",
    "\n",
    "ets = EventTimesSampler(d_times=d_times, j_event_types=j_events)\n",
    "\n",
    "seed = 0\n",
    "means_vector = np.zeros(n_cov)\n",
    "covariance_matrix = 0.4*np.identity(n_cov)\n",
    "clip_value = 1.5\n",
    "\n",
    "covariates = [f'Z{i + 1}' for i in range(n_cov)]\n",
    "\n",
    "patients_df = pd.DataFrame(data=pd.DataFrame(data=np.random.multivariate_normal(means_vector, covariance_matrix,\n",
    "                                                                                size=n_patients),\n",
    "                                             columns=covariates))\n",
    "patients_df.clip(lower= -1 * clip_value, upper=clip_value, inplace=True)\n",
    "patients_df = ets.sample_event_times(patients_df, hazard_coefs=real_coef_dict, seed=seed)\n",
    "patients_df = ets.sample_independent_lof_censoring(patients_df, prob_lof_at_t=0.01 * np.ones_like(ets.times),\n",
    "                                                   seed=seed + 1)\n",
    "patients_df = ets.update_event_or_lof(patients_df)\n",
    "patients_df.index.name = 'pid'\n",
    "patients_df = patients_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pydts.examples_utils.plots import plot_events_occurrence\n",
    "plot_events_occurrence(patients_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_df.groupby(['X', 'J']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "step = 0.25\n",
    "penalizers = np.arange(-9, -3.6, step=step) \n",
    "n_splits = 5\n",
    "\n",
    "cross_validators = {}\n",
    "\n",
    "for idp, penalizer in enumerate(penalizers):\n",
    "    print(f\"Started Penalizer: {penalizer}, {idp+1}/{len(penalizers)}\")\n",
    "    fit_beta_kwargs = {\n",
    "            'model_kwargs': {\n",
    "            'penalizer': np.exp(penalizer),\n",
    "            'l1_ratio': 1\n",
    "        }\n",
    "    }\n",
    "    start = time()\n",
    "    cross_validators[penalizer] = TwoStagesCV()\n",
    "    cross_validators[penalizer].cross_validate(full_df=patients_df, n_splits=n_splits, seed=seed, nb_workers=1, \n",
    "                                               fit_beta_kwargs=fit_beta_kwargs,\n",
    "                                               metrics=['PE', 'AUC', 'IAUC', 'GAUC'])\n",
    "    end = time()\n",
    "    print(f\"Finished Penalizer: {penalizer}, {idp+1}/{len(penalizers)}, {int(end-start)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "cross_validator_null = TwoStagesCV()\n",
    "cross_validator_null.cross_validate(full_df=patients_df, n_splits=n_splits, seed=seed, nb_workers=1, \n",
    "                                    metrics=['PE', 'AUC', 'IAUC', 'GAUC'])\n",
    "end = time()\n",
    "print(f\"Finished {int(end-start)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = patients_df.groupby(['J', 'X']).size().unstack('J').fillna(0)\n",
    "\n",
    "ticksize = 13\n",
    "axes_title_fontsize = 15\n",
    "legend_size = 12\n",
    "\n",
    "risk_names = ['J=1', 'J=2']\n",
    "risk_colors = ['tab:blue', 'tab:green']\n",
    "risk_letters = ['d', 'e', 'f', 'g', 'h', 'i']\n",
    "chosen_lambda = -5.75\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(17, 14))\n",
    "\n",
    "ax = axes[0, 0]\n",
    "add_panel_text(ax, 'a')\n",
    "ax.tick_params(axis='both', which='major', labelsize=ticksize)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=ticksize)\n",
    "ax.set_xlabel(r'Log ($\\lambda$)', fontsize=axes_title_fontsize)\n",
    "ax.set_ylabel(r'Global AUC', fontsize=axes_title_fontsize)\n",
    "\n",
    "penalizers_x, mean_gauc, std_gauc = [], [], []\n",
    "for penalizer in sorted(cross_validators.keys()):\n",
    "    ser = pd.Series(cross_validators[penalizer].global_auc)\n",
    "    penalizers_x.append(penalizer)\n",
    "    mean_gauc.append(ser.mean())\n",
    "    std_gauc.append(ser.std())\n",
    "\n",
    "ax.errorbar(penalizers_x, mean_gauc, yerr=std_gauc, fmt=\"o\", color='g', alpha=0.5, label='With Penalization')\n",
    "ax.axhline(pd.Series(cross_validator_null.global_auc).mean(), ls = '--', label='Without Penalization', color='tab:blue')\n",
    "ax.axvline(chosen_lambda, color='brown', ls='-.', label=r'Chosen $\\lambda$')\n",
    "ax.legend(fontsize=legend_size)\n",
    "#ax.set_ylim([0.53, 0.78])\n",
    "\n",
    "\n",
    "ax = axes[0, 1]\n",
    "add_panel_text(ax, 'b')\n",
    "ax.tick_params(axis='both', which='major', labelsize=ticksize)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=ticksize)\n",
    "ax.set_xlabel(r'Log ($\\lambda$)', fontsize=axes_title_fontsize)\n",
    "ax.set_ylabel(r'Integrated AUC', fontsize=axes_title_fontsize)\n",
    "\n",
    "fig_mean = pd.DataFrame()\n",
    "fig_std = pd.DataFrame()\n",
    "for p in sorted(cross_validators.keys()):\n",
    "    iauc_df = pd.DataFrame.from_dict(cross_validators[p].integrated_auc)\n",
    "    mean_ser = pd.DataFrame.from_dict(cross_validators[p].integrated_auc).mean(axis=1)\n",
    "    mean_ser.name = penalizer\n",
    "    std_ser = pd.DataFrame.from_dict(cross_validators[p].integrated_auc).std(axis=1)\n",
    "    std_ser.name = penalizer\n",
    "    fig_mean = pd.concat([fig_mean, mean_ser], axis=1)\n",
    "    fig_std = pd.concat([fig_std, std_ser], axis=1)\n",
    "\n",
    "for risk in range(1,3):\n",
    "    ax.errorbar(penalizers_x, fig_mean.loc[risk], yerr=fig_std.loc[risk], fmt=\"o\", color=risk_colors[risk-1], alpha=0.5, label=f'{risk_names[risk-1]} - With Penalization')\n",
    "    ax.axhline(pd.DataFrame.from_dict(cross_validator_null.integrated_auc).mean(axis=1).loc[risk], ls = '--', label=f'{risk_names[risk-1]} - Without Penalization', color=risk_colors[risk-1])\n",
    "#ax.set_ylim([0.53, 0.78])\n",
    "ax.axvline(chosen_lambda, color='brown', ls='-.', label=r'Chosen $\\lambda$')\n",
    "ax.legend(loc='lower left', fontsize=legend_size)\n",
    "\n",
    "for risk in range(1, 3):\n",
    "    for idp, penalizer in enumerate(cross_validators.keys()):\n",
    "\n",
    "        tmp_j1_params_df = pd.DataFrame()\n",
    "        for i_fold in range(n_splits):\n",
    "            tmp_j1_params_df = pd.concat([tmp_j1_params_df, cross_validators[penalizer].models[i_fold].beta_models[risk].params_], axis=1)\n",
    "\n",
    "        ser_1 = tmp_j1_params_df.mean(axis=1) \n",
    "        ser_1.name = penalizer\n",
    "\n",
    "        if idp == 0:\n",
    "            j1_params_df = ser_1.to_frame()\n",
    "        else:\n",
    "            j1_params_df = pd.concat([j1_params_df, ser_1], axis=1)\n",
    "\n",
    "\n",
    "    ax = axes[1, risk-1]\n",
    "    add_panel_text(ax, risk_letters[risk-1])\n",
    "    ax.tick_params(axis='both', which='major', labelsize=ticksize)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=ticksize)\n",
    "    for i in range(len(j1_params_df)):\n",
    "        ax.plot(penalizers_x, j1_params_df.iloc[i].values, lw=1)\n",
    "\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(f'{n_splits}-Fold Mean Coefficient Value', fontsize=axes_title_fontsize)\n",
    "            ax.set_xlabel(r'Log ($\\lambda$)', fontsize=axes_title_fontsize)\n",
    "            ax.set_title(rf'$\\beta_{risk}$', fontsize=axes_title_fontsize)\n",
    "            ax.axvline(chosen_lambda, color='brown', ls='-.', label=r'Chosen $\\lambda$')\n",
    "\n",
    "    ax = axes[risk-1, 2]\n",
    "    \n",
    "    for idp, penalizer in enumerate(cross_validators.keys()):\n",
    "        tmp_ser = j1_params_df[penalizer].round(3)\n",
    "        count = (tmp_ser.abs() > 0).sum()\n",
    "        if idp == 0:\n",
    "            ax.scatter(penalizer, count, color=risk_colors[risk-1], alpha=0.8, marker='P', label=f'{risk_names[risk-1]}')\n",
    "        else:\n",
    "            ax.scatter(penalizer, count, color=risk_colors[risk-1], alpha=0.8, marker='P')\n",
    "\n",
    "ax = axes[0, 2]       \n",
    "add_panel_text(ax, 'c')\n",
    "ax.tick_params(axis='both', which='major', labelsize=ticksize)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=ticksize)\n",
    "ax.set_xlabel(r'Log ($\\lambda$)', fontsize=axes_title_fontsize)\n",
    "ax.set_ylabel(f'Number of Non-Zero Coefficients', fontsize=axes_title_fontsize)\n",
    "ax.axvline(chosen_lambda, color='brown', ls='-.', label=r'Chosen $\\lambda$')\n",
    "ax.axhline(5, color='k', alpha=0.5, label='True value', ls='--')\n",
    "ax.legend(loc='upper right', fontsize=legend_size)\n",
    "ax.set_ylim([0,103])\n",
    "\n",
    "ax = axes[1, 2]       \n",
    "add_panel_text(ax, 'f')\n",
    "ax.tick_params(axis='both', which='major', labelsize=ticksize)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=ticksize)\n",
    "ax.set_xlabel(r'Log ($\\lambda$)', fontsize=axes_title_fontsize)\n",
    "ax.set_ylabel(f'Number of Non-Zero Coefficients', fontsize=axes_title_fontsize)\n",
    "ax.axvline(chosen_lambda, color='brown', ls='-.', label=r'Chosen $\\lambda$')\n",
    "ax.axhline(5, color='k', alpha=0.3, label='True value', ls='--')\n",
    "ax.legend(loc='upper right', fontsize=legend_size)\n",
    "ax.set_ylim([0,103])\n",
    "\n",
    "for risk in range(1, 3):\n",
    "    ax = axes[2, risk-1]\n",
    "    add_panel_text(ax, risk_letters[3+risk-1])\n",
    "    ax.tick_params(axis='both', which='major', labelsize=ticksize)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=ticksize)\n",
    "    mean_auc = cross_validators[chosen_lambda].results.loc[slicer['AUC', :, risk]].mean()\n",
    "    std_auc = cross_validators[chosen_lambda].results.loc[slicer['AUC', :, risk]].std()\n",
    "    ax.errorbar(mean_auc.index, mean_auc.values, yerr=std_auc.values, fmt=\"o\", color=risk_colors[risk-1], alpha=0.8)\n",
    "    ax.set_yticks(np.arange(0, 1.1, 0.1))\n",
    "    ax.set_yticklabels([c.round(1) for c in np.arange(0, 1.1, 0.1)])\n",
    "    ax.set_xlabel(r'Time', fontsize=axes_title_fontsize)\n",
    "    ax.set_ylabel(f'AUC (t)', fontsize=axes_title_fontsize)\n",
    "    ax.set_title(fr'{risk_names[risk-1]}, Log ($\\lambda$) = {chosen_lambda}', fontsize=axes_title_fontsize)\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.axhline(0.5, ls='--', color='k', alpha=0.5)\n",
    "    ax.set_xticks(list(range(1, d_times+1)))\n",
    "    ax.set_xticklabels(list(range(1, d_times+1)))\n",
    "    \n",
    "    ax2 = ax.twinx()\n",
    "    ax2.bar(counts.index, counts[risk].values.squeeze(), color='r', alpha=0.8, width=0.4)\n",
    "    ax2.set_ylabel('Number of observed events', fontsize=axes_title_fontsize, color='r')\n",
    "    ax2.tick_params(axis='y', colors='r')\n",
    "    ax2.set_ylim([0, 1800])\n",
    "    ax2.tick_params(axis='both', which='major', labelsize=ticksize)\n",
    "    ax2.tick_params(axis='both', which='minor', labelsize=ticksize)\n",
    "    \n",
    "\n",
    "ax = axes[2,2]\n",
    "add_panel_text(ax, 'i')\n",
    "mean_pe = cross_validators[chosen_lambda].results.loc[slicer['PE', :, 1]].mean()\n",
    "std_pe = cross_validators[chosen_lambda].results.loc[slicer['PE', :, 1]].std()\n",
    "ax.errorbar(mean_pe.index, mean_pe.values, yerr=std_pe.values, fmt=\"v\", color=risk_colors[0], alpha=0.8, \n",
    "            label=risk_names[0])\n",
    "mean_pe = cross_validators[chosen_lambda].results.loc[slicer['PE', :, 2]].mean()\n",
    "std_pe = cross_validators[chosen_lambda].results.loc[slicer['PE', :, 2]].std()\n",
    "ax.errorbar(mean_pe.index, mean_pe.values, yerr=std_pe.values, fmt=\"v\", color=risk_colors[1], alpha=0.8,\n",
    "            label=risk_names[1])\n",
    "ax.set_ylabel('PE (t)', fontsize=axes_title_fontsize)\n",
    "ax.set_ylim([0, 0.17])\n",
    "ax.tick_params(axis='both', which='major', labelsize=ticksize)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=ticksize)\n",
    "ax.legend(loc='lower right', fontsize=legend_size)\n",
    "ax.set_xticks(list(range(1, d_times+1)))\n",
    "ax.set_xticklabels(list(range(1, d_times+1)))\n",
    "ax.set_title(fr'Log ($\\lambda$) = {chosen_lambda}', fontsize=axes_title_fontsize)\n",
    "ax.set_xlabel(r'Time', fontsize=axes_title_fontsize)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(os.path.join(OUTPUT_DIR, 'regularization_sim.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_positives_df = pd.DataFrame()\n",
    "\n",
    "for risk in range(1, j_events+1):\n",
    "    for idp, penalizer in enumerate(cross_validators.keys()):\n",
    "        tmp_j1_params_df = pd.DataFrame()\n",
    "        for i_fold in range(n_splits):\n",
    "            tmp_j1_params_df = pd.concat([tmp_j1_params_df, cross_validators[penalizer].models[i_fold].beta_models[risk].params_], axis=1)\n",
    "\n",
    "        ser_1 = tmp_j1_params_df.mean(axis=1) \n",
    "        ser_1.name = penalizer\n",
    "\n",
    "        if idp == 0:\n",
    "            j1_params_df = ser_1.to_frame()\n",
    "        else:\n",
    "            j1_params_df = pd.concat([j1_params_df, ser_1], axis=1)\n",
    "            \n",
    "        j1_params_df = j1_params_df.round(4)  \n",
    "        \n",
    "        true_positives = (j1_params_df.abs() > 0).iloc[:5].sum()\n",
    "        true_positives.name = 'True Positives'\n",
    "        false_positives = (j1_params_df.abs() > 0).iloc[5:].sum()\n",
    "        false_positives.name = 'False Positives'\n",
    "\n",
    "        positives_df = pd.concat([true_positives, false_positives], axis=1)\n",
    "        positives_df.index.name = r'Log ($\\lambda$)'\n",
    "    total_positives_df = pd.concat([total_positives_df, pd.concat([positives_df], keys=[fr'$\\beta_{risk}$'], axis=1)], axis=1)\n",
    "\n",
    "total_positives_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_positives_df.to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk = 1\n",
    "penalizer = chosen_lambda\n",
    "tmp_j1_params_df = pd.DataFrame()\n",
    "j1_params_df =  pd.DataFrame()\n",
    "for i_fold in range(n_splits):\n",
    "    tmp_j1_params_df = pd.concat([tmp_j1_params_df, cross_validators[penalizer].models[i_fold].beta_models[risk].params_], axis=1)\n",
    "\n",
    "ser_1 = tmp_j1_params_df.mean(axis=1).round(4)  \n",
    "ser_1.name = rf'$Log (\\lambda$)={penalizer}'\n",
    "\n",
    "true_values = pd.Series(beta1[:5], name='True Value', index=[f'Z{i}' for i in range(1,6)])\n",
    "\n",
    "for i_fold in range(n_splits):\n",
    "    tmp_j1_params_df = pd.concat([tmp_j1_params_df, cross_validator_null.models[i_fold].beta_models[risk].params_], axis=1)\n",
    "\n",
    "null_ser = tmp_j1_params_df.mean(axis=1).round(4)  \n",
    "null_ser.name = rf'Without Penalization'\n",
    "\n",
    "values_df = pd.concat([true_values, null_ser.iloc[:5], ser_1.iloc[:5]], axis=1)\n",
    "values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk = 2\n",
    "penalizer = chosen_lambda\n",
    "tmp_j1_params_df = pd.DataFrame()\n",
    "j1_params_df =  pd.DataFrame()\n",
    "for i_fold in range(n_splits):\n",
    "    tmp_j1_params_df = pd.concat([tmp_j1_params_df, cross_validators[penalizer].models[i_fold].beta_models[risk].params_], axis=1)\n",
    "\n",
    "ser_1 = tmp_j1_params_df.mean(axis=1).round(4)  \n",
    "ser_1.name = rf'$Log (\\lambda$)={penalizer}'\n",
    "\n",
    "true_values = pd.Series(beta2[:5], name='True Value', index=[f'Z{i}' for i in range(1,6)])\n",
    "\n",
    "for i_fold in range(n_splits):\n",
    "    tmp_j1_params_df = pd.concat([tmp_j1_params_df, cross_validator_null.models[i_fold].beta_models[risk].params_], axis=1)\n",
    "\n",
    "null_ser = tmp_j1_params_df.mean(axis=1).round(4)  \n",
    "null_ser.name = rf'Without Penalization'\n",
    "\n",
    "values_df = pd.concat([true_values, null_ser.iloc[:5], ser_1.iloc[:5]], axis=1)\n",
    "values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join(OUTPUT_DIR, 'reg_cross_validators.pkl'), 'wb') as f:\n",
    "#     pickle.dump(cross_validators, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(OUTPUT_DIR, 'reg_cross_validators.pkl'), 'rb') as f:\n",
    "    cross_validators = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j1_params_df = pd.DataFrame()\n",
    "\n",
    "for idp, penalizer in enumerate(cross_validators.keys()):\n",
    "    tmp_j1_params_df = pd.DataFrame()\n",
    "    for i_fold in range(n_splits):\n",
    "        tmp_j1_params_df = pd.concat([tmp_j1_params_df, \n",
    "                cross_validators[penalizer].models[i_fold].alpha_df.set_index(['J', 'X'])['alpha_jt']], axis=1)\n",
    "\n",
    "    ser_1 = tmp_j1_params_df.mean(axis=1) \n",
    "    ser_1.name = penalizer\n",
    "\n",
    "    if idp == 0:\n",
    "        j1_params_df = ser_1.to_frame()\n",
    "    else:\n",
    "        j1_params_df = pd.concat([j1_params_df, ser_1], axis=1)\n",
    "\n",
    "    j1_params_df = j1_params_df.round(4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(11, 4))\n",
    "\n",
    "s=12\n",
    "\n",
    "_plot_pen = [-9, -8, -7, -6, -5, -4]\n",
    "ax = axes[0]\n",
    "add_panel_text(ax, 'a')\n",
    "risk = 1\n",
    "for penalizer in _plot_pen:\n",
    "    ax.scatter(range(1,16), j1_params_df.loc[slicer[risk, :], penalizer].values, label=str(penalizer), s=s)\n",
    "    ax.set_xticks(list(range(1,16)))\n",
    "ax.plot(list(range(1,16)), [real_coef_dict['alpha'][risk](t) for t in range(1,16)], ls='--', color='k', label='True')\n",
    "ax.set_xticklabels([str(l) for l in list(range(1,16))])\n",
    "ax.set_ylabel(r'$\\alpha_{1t}$', fontsize=15)\n",
    "ax.set_xlabel('Time', fontsize=15)\n",
    "ax.legend(title=r\"Log $\\lambda$\")\n",
    "ax.set_ylim([-4.1, -2.2])\n",
    "\n",
    "ax = axes[1]\n",
    "add_panel_text(ax, 'b')\n",
    "\n",
    "risk = 2\n",
    "for penalizer in _plot_pen:\n",
    "    ax.scatter(range(1,16), j1_params_df.loc[slicer[risk, :], penalizer].values, label=str(penalizer), s=s)\n",
    "    ax.set_xticks(list(range(1,16)))\n",
    "ax.plot(list(range(1,16)), [real_coef_dict['alpha'][risk](t) for t in range(1,16)], ls='--', color='k', label='True')\n",
    "ax.set_xticklabels([str(l) for l in list(range(1,16))])\n",
    "ax.set_ylabel(r'$\\alpha_{2t}$', fontsize=15)\n",
    "ax.set_xlabel('Time', fontsize=15)\n",
    "ax.legend(title=r\"Log $\\lambda$\")\n",
    "ax.set_ylim([-4.1, -2.2])\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(os.path.join(OUTPUT_DIR, 'regularization_alpha_sim.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39-dtsp",
   "language": "python",
   "name": "py39-dtsp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
